{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction d'un système de recommandation\n",
    "\n",
    "Nous avons décidé d'orienter notre projet sur la recommendation de films.\n",
    "En effet durant ce confinement, nous avons eu le temps de visionner beaucoup de films,\n",
    "mais nous nous sommes rendus compte que nous passions quasiment autant de temps\n",
    "à choisir le film qu'à le regarder. D'où la nécessité de créer un système de re-\n",
    "commendations afin d'optimiser notre temps de visionnage.\n",
    "Nous avons chercher une base de données assez exploitable afin de mener à bien\n",
    "notre projet. Nous nous sommes basés sur la base de données de 'The Movies Dataset'.\n",
    "\n",
    "[sommaire](#sommaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reste à faire\n",
    "\n",
    "- [ ] approche linéaire \n",
    "- [ ] class hybride\n",
    "- [ ] CV grid search pour model-based hyperparamètres\n",
    "- [ ] comparer score pour les prédicteurs\n",
    "- [ ] comparer score pour les predicteurs hybride (devrait être moindre)\n",
    "- [ ] documentation docstring\n",
    "- [ ] documentation markdown\n",
    "\n",
    "# À dire dans rapport pdf\n",
    "\n",
    "- utilisation des magic command timeit, lprun pour optimiser le code, trop lent au début, on a réussi à accélérer tout ça en utilisant des numpy array quand c'était possible et en indexant ratings avec userId et movieId pour des accès plus direct (note d'Anita : est ce qu'on a bien fait ça tout le temps ? moi oui mais j'ai pas regardé pour vos fonctions)\n",
    "- présentation succinte des différentes méthodes implémentée\n",
    "- que la plupart du temps, on donne les hyperparametres en arguments mais qu'on leur donne nos valeurs pref apr défaut. Comme ça, ça peut tourner avec nos choix d'hyperparam, mais que l'utilisateur peut quand même avoir la main dessus\n",
    "- sources de nos inspi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importation des packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement et nettoyage des données\n",
    "\n",
    "<span style=\"color:blue\"> description des différentes tables </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anita/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(\"movies_metadata.csv\")\n",
    "ratings = pd.read_csv(\"ratings_small.csv\")\n",
    "keywords = pd.read_csv(\"keywords.csv\")\n",
    "credits = pd.read_csv(\"tmdb_5000_credits.csv\")\n",
    "link = pd.read_csv(\"links_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>862</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8844</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15602</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31357</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11862</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           keywords\n",
       "0    862  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...\n",
       "1   8844  [{'id': 10090, 'name': 'board game'}, {'id': 1...\n",
       "2  15602  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...\n",
       "3  31357  [{'id': 818, 'name': 'based on novel'}, {'id':...\n",
       "4  11862  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n..."
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>[{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...</td>\n",
       "      <td>[{\"credit_id\": \"52fe48009251416c750aca23\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>[{\"cast_id\": 4, \"character\": \"Captain Jack Spa...</td>\n",
       "      <td>[{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>206647</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>[{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...</td>\n",
       "      <td>[{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>49026</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>[{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...</td>\n",
       "      <td>[{\"credit_id\": \"52fe4781c3a36847f81398c3\", \"de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>49529</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>[{\"cast_id\": 5, \"character\": \"John Carter\", \"c...</td>\n",
       "      <td>[{\"credit_id\": \"52fe479ac3a36847f813eaa3\", \"de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                     title  \\\n",
       "0     19995                                    Avatar   \n",
       "1       285  Pirates of the Caribbean: At World's End   \n",
       "2    206647                                   Spectre   \n",
       "3     49026                     The Dark Knight Rises   \n",
       "4     49529                               John Carter   \n",
       "\n",
       "                                                cast  \\\n",
       "0  [{\"cast_id\": 242, \"character\": \"Jake Sully\", \"...   \n",
       "1  [{\"cast_id\": 4, \"character\": \"Captain Jack Spa...   \n",
       "2  [{\"cast_id\": 1, \"character\": \"James Bond\", \"cr...   \n",
       "3  [{\"cast_id\": 2, \"character\": \"Bruce Wayne / Ba...   \n",
       "4  [{\"cast_id\": 5, \"character\": \"John Carter\", \"c...   \n",
       "\n",
       "                                                crew  \n",
       "0  [{\"credit_id\": \"52fe48009251416c750aca23\", \"de...  \n",
       "1  [{\"credit_id\": \"52fe4232c3a36847f800b579\", \"de...  \n",
       "2  [{\"credit_id\": \"54805967c3a36829b5002c41\", \"de...  \n",
       "3  [{\"credit_id\": \"52fe4781c3a36847f81398c3\", \"de...  \n",
       "4  [{\"credit_id\": \"52fe479ac3a36847f813eaa3\", \"de...  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_correct_id(word):\n",
    "    if not isinstance(word, str) or re.fullmatch(r'[0-9]+', word):\n",
    "        return word\n",
    "    return \"wrong_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_genre(l):\n",
    "    if len(l) <= 0 :\n",
    "        return []\n",
    "    if isinstance(l[0], dict):\n",
    "        return [d['name'] for d in l]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> explication du nettoyage effectué </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not re-run !\n",
    "\n",
    "movies = movies.drop_duplicates('id')\n",
    "keywords = keywords.drop_duplicates('id')\n",
    "credits = credits.drop_duplicates('movie_id')\n",
    "\n",
    "movies.id = movies.id.apply(filter_correct_id)\n",
    "movies = movies[movies.id != \"wrong_id\"]\n",
    "movies.id = movies.id.astype('int64')\n",
    "movies[movies['vote_count'].notnull()]['vote_count'].astype('int64', copy=False)\n",
    "movies[movies['vote_average'].notnull()]['vote_average'].astype('int64', copy=False)\n",
    "\n",
    "ratings = ratings.drop(columns=['timestamp'])\n",
    "\n",
    "movies = movies.rename(columns={'id' : 'tmdbId'})\n",
    "keywords = keywords.rename(columns={'id' : 'tmdbId'})\n",
    "credits = credits.rename(columns={'movie_id' : 'tmdbId'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sommaire <a id='sommaire'></a>\n",
    "\n",
    "Nous avons différenciés deux types de systèmes de recommendations. \n",
    "\n",
    "- Les **Recommender** recommendent à un utilisateurs des films qu'il sera susceptible d'aimer, sans explicitement prédire la note que l'utilisateur donnera à ses films. Nous en avons implémenté deux types:\n",
    "\n",
    "    1. un système utilisant la popularité des films dans une catégorie donnée [popularity-based](#popularity)\n",
    "    2. un système utilisant les méta-informations des films [clustering](#clustering)\n",
    "\n",
    "\n",
    "- Les **Predictor** prédisent les notes que des utilisateurs donneront à des films. Nous en avons implémenté deux types :\n",
    "    3. un système basé sur les données connues (user- et item-based présenté en cours) [memory-based](#memory)\n",
    "    4. un système basé sur un modèle [model-based](#model)\n",
    "\n",
    "\n",
    "- Les systèmes **Hybride** font le mélange des deux. Ils recommendent à un utilisateur des films qu'il sera susceptible d'aimer en utilisant des prédictions de notes. Nous avons implémenté une classe qui prend en argument un Recommender et un Predictor:\n",
    "    5. [hybride](#hybride)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Films les plus populaires par genre <a id='popularity'></a>\n",
    "\n",
    "\n",
    "Une méthode simple pour recommander des films à un utilisateur, est de lui présenter la liste des films les plus populaires appartenant à ses genres préférées. Ainsi il faudra dans un premier temps identifier ses genres préférés, puis établir la liste des films les plus populaires qui figurent parmi ces genres.\n",
    "\n",
    "Pour cette méthode, nous allons utiliser les données contenues dans les colonnes `vote_average` et `vote_count`. En effet, il y a plus de votes récoltés dans cette table quand dans `ratings`. Les utilisateurs ont utilisé une notation allant de 0 à 10.\n",
    "\n",
    "L'initialisation d'un objet de `PopularityRecommender` traite les données entrée pour rendre la recommendation plus efficace. La dataframe `dfm` de schéma *dfm(movieId, title, vote_average, vote_count)* contient la liste des films identifiés par leur `movieId`. Pour pouvoir sélectionner les films par genre, et parce qu'un film peut appartenir à plusieurs genres, nous utlisons une table `sgr` dans laquelle chaque ligne n'indique qu'un seul genre du film. Indexer ces deux tables par l'attribut `movieId` nous permet d'accélerer la sélection des lignes puisqu'elle ne se fait presque que par `movieId`. Enfin, la table `dfm` contient les notes des utilisateurs et des films. Elle est utilisée pour déterminer les genres préféres d'un user donné : la méthode `pref_genres` selectionne les genres des 3 films préférés de l'utilisateurs. \n",
    "\n",
    "\n",
    "<span style=\"color:blue\"> selection des genres peut être à faire de manière plus accurate ? genre donner plus d'importance à un certain genre ? </span>\n",
    "\n",
    "<span style=\"color:blue\"> utilisation d'une fonction extérieure à la classe : même problème avec memory et les fct de corrélations </span>\n",
    "\n",
    "\n",
    "Pour évaluer la popularitée d'un film au sein d'un catégorie de films, nous utilisons la formule de *weighted rating* utilisée par le site TMDB : \n",
    "$$\n",
    "WR = \\frac{v}{v + m} R + \\frac{m}{v +m} C\n",
    "$$\n",
    "\n",
    "où \n",
    "- $R$ est la note moyenne du film (vote_average) ;\n",
    "\n",
    "- $v$ est le nombre de notes que le film a reçu (vote_count) ; \n",
    "\n",
    "- $m$ est le nombre minimum de votes qu'un film doit recevoir pour pouvoir figurer sur la liste ;\n",
    "\n",
    "- $C$ est la note moyenne donnée dans toute l'étude.\n",
    "\n",
    "\n",
    "Si $R$, $v$ et $C$ se calculent à partir des données, il nous faut choisir le seuil $m$. Nous allons considérer qu'un film doit avoir eu plus de votes qu'au moins 80% des films pour pouvoir aparaître dans le top du genre. Ce paramètre permet de ne considérer que des films qui ont été vu par une majorité de personnes et qui peuvent être donc considérés comme populaire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating(x, m):\n",
    "        '''\n",
    "        :param: x une matrice numpy de format suivant\n",
    "                    chaque ligne correspond à un films\n",
    "                    la première colonne x[: 0] contient le nombre de votes reçus par le films\n",
    "                    la deuxième colonne x[: 1] content la note moyenne de chaque film\n",
    "                m le nombre minimum de votes qu'un film doit recevoir pour pouvoir figurer sur la liste\n",
    "        :return: un numpy array contenant la note pondérée que chaque film\n",
    "        '''\n",
    "        v = x[:, 0] # liste du nombre de vote\n",
    "        R = x[:, 1] # liste des notes moyennes\n",
    "        C = sum(np.multiply(v, R)) / sum(v) # note moyenne attribuée\n",
    "        return np.multiply(v/(v+m), R) + np.multiply(m/(m+v), C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self, movies, ratings, link):\n",
    "        \n",
    "        self.dfr = ratings[['userId', 'movieId', 'rating']].set_index(['userId', 'movieId'])\n",
    "        \n",
    "        # construction de la table des films identifiés par leur movieId\n",
    "        self.dfm = movies[['tmdbId', 'title', 'genres', 'vote_average', 'vote_count']]\n",
    "        self.dfm = link.merge(self.dfm, left_on='tmdbId', right_on='tmdbId').drop(columns=['tmdbId', 'imdbId'])\n",
    "        self.dfm.set_index('movieId', inplace=True)\n",
    "        \n",
    "        # transformer la description JSON de genres en liste de string plus simple à manipuler\n",
    "        self.dfm['genres'] = self.dfm['genres']\\\n",
    "                    .apply(lambda x: literal_eval(x) if isinstance(x, str) else x)\\\n",
    "                    .apply(simplify_genre)\n",
    "\n",
    "        # construction d'une série dans laquelle les lignes ne contiennent qu'un seul genre\n",
    "        self.sgr = self.dfm.apply(lambda x: pd.Series(x['genres'], dtype='str'),axis=1).stack().reset_index(level=1, drop=True)\n",
    "        self.sgr.name = 'genre'\n",
    "                \n",
    "    def recommend(self, uid, n=20):\n",
    "        '''\n",
    "        :param: uid l'identifiant de l'utilisateur\n",
    "                n le nombre de films à recommender\n",
    "        :return: une dataframe contenant les n films les plus populaires appartenant aux genres préférés de l'user uid\n",
    "        '''\n",
    "        \n",
    "        # récupérer les films les plus populaires des genres préférés de uid\n",
    "        chart = self._best_(self.pref_genres(uid), n*10)\n",
    "        \n",
    "        # ne retenir que les films non encore visionnés\n",
    "        watched_movies = self.dfr.loc[uid, :].index.unique()\n",
    "        watched_movies = chart.index.isin(watched_movies)\n",
    "        chart = chart.loc[~watched_movies]\n",
    "\n",
    "        return chart.head(n) if len(chart) > n else chart\n",
    "    \n",
    "\n",
    "    def pref_genres(self, uid):\n",
    "        '''\n",
    "        :param: uid l'identifiant de l'utilisateur\n",
    "        :return: une liste des genres des 3 films préférés de l'user uid\n",
    "        '''\n",
    "        rats = self.dfr.loc[uid, :].sort_values(by='rating', ascending=False)\n",
    "        pref = rats.head(3).index if rats.shape[0] > 5 else rats.index\n",
    "        genres = []\n",
    "        for g in self.dfm.loc[pref].genres :\n",
    "            genres = list(set(genres) | set(g))\n",
    "        return genres\n",
    "\n",
    "    def _best_(self, genres, k=200):\n",
    "        '''\n",
    "        :param: genres une liste de genres sous forme de str\n",
    "                k le nombre de films à retenir\n",
    "        :return: les k films les plus populaires appartenant à au moins un genre dans la liste genres\n",
    "        '''\n",
    "        # select movies that are in genres\n",
    "        dfg = self.sgr[self.sgr.isin(genres)]\n",
    "        dfg = self.dfm.loc[dfg.index.drop_duplicates()] \n",
    "        # need to drop duplicates : a movie can be selected because 2 or more of its genres are ok\n",
    "\n",
    "        m = dfg.vote_count.quantile(0.8)\n",
    "        \n",
    "        # sort movies by decresing weighted rating\n",
    "        top = dfg[(dfg['vote_count'] >= m)]\n",
    "        top['wr'] = weighted_rating(top[['vote_count', 'vote_average']].to_numpy(), m)\n",
    "        top.sort_values('wr', ascending=False, inplace=True)\n",
    "\n",
    "        # drop unnecessary columns\n",
    "        top.drop(columns=['vote_count', 'vote_average'], inplace=True)\n",
    "\n",
    "        return top.head(k) if len(top) > k else top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.88 s ± 725 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pop = PopularityRecommender(movies, ratings, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Family', 'Comedy', 'Science Fiction', 'Mystery', 'Animation', 'Thriller', 'Fantasy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anita/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/anita/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/anita/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>wr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58559</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>[Drama, Action, Crime, Thriller]</td>\n",
       "      <td>8.229929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>[Thriller, Crime]</td>\n",
       "      <td>8.202805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>8.104162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>Spirited Away</td>\n",
       "      <td>[Fantasy, Adventure, Animation, Family]</td>\n",
       "      <td>8.103355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>Life Is Beautiful</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>8.088389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>[Adventure, Action, Science Fiction]</td>\n",
       "      <td>8.073076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92259</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>[Drama, Comedy]</td>\n",
       "      <td>8.060714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79132</th>\n",
       "      <td>Inception</td>\n",
       "      <td>[Action, Thriller, Science Fiction, Mystery, A...</td>\n",
       "      <td>8.047071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109487</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>[Adventure, Drama, Science Fiction]</td>\n",
       "      <td>8.034133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Leon: The Professional</td>\n",
       "      <td>[Thriller, Crime, Drama]</td>\n",
       "      <td>8.029094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  \\\n",
       "movieId                            \n",
       "58559            The Dark Knight   \n",
       "296                 Pulp Fiction   \n",
       "356                 Forrest Gump   \n",
       "5618               Spirited Away   \n",
       "2324           Life Is Beautiful   \n",
       "1196     The Empire Strikes Back   \n",
       "92259           The Intouchables   \n",
       "79132                  Inception   \n",
       "109487              Interstellar   \n",
       "293       Leon: The Professional   \n",
       "\n",
       "                                                    genres        wr  \n",
       "movieId                                                               \n",
       "58559                     [Drama, Action, Crime, Thriller]  8.229929  \n",
       "296                                      [Thriller, Crime]  8.202805  \n",
       "356                               [Comedy, Drama, Romance]  8.104162  \n",
       "5618               [Fantasy, Adventure, Animation, Family]  8.103355  \n",
       "2324                                       [Comedy, Drama]  8.088389  \n",
       "1196                  [Adventure, Action, Science Fiction]  8.073076  \n",
       "92259                                      [Drama, Comedy]  8.060714  \n",
       "79132    [Action, Thriller, Science Fiction, Mystery, A...  8.047071  \n",
       "109487                 [Adventure, Drama, Science Fiction]  8.034133  \n",
       "293                               [Thriller, Crime, Drama]  8.029094  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop = PopularityRecommender(movies, ratings, link)\n",
    "print(pop.pref_genres(100))\n",
    "pop.recommend(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15273</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15274</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15275</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15276</th>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15277</th>\n",
       "      <td>100</td>\n",
       "      <td>25</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15278</th>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15279</th>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15280</th>\n",
       "      <td>100</td>\n",
       "      <td>62</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15281</th>\n",
       "      <td>100</td>\n",
       "      <td>86</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15282</th>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15283</th>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15284</th>\n",
       "      <td>100</td>\n",
       "      <td>135</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15285</th>\n",
       "      <td>100</td>\n",
       "      <td>141</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15286</th>\n",
       "      <td>100</td>\n",
       "      <td>608</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15287</th>\n",
       "      <td>100</td>\n",
       "      <td>648</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15288</th>\n",
       "      <td>100</td>\n",
       "      <td>661</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15289</th>\n",
       "      <td>100</td>\n",
       "      <td>708</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15290</th>\n",
       "      <td>100</td>\n",
       "      <td>733</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15291</th>\n",
       "      <td>100</td>\n",
       "      <td>736</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15292</th>\n",
       "      <td>100</td>\n",
       "      <td>745</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15293</th>\n",
       "      <td>100</td>\n",
       "      <td>780</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15294</th>\n",
       "      <td>100</td>\n",
       "      <td>786</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15295</th>\n",
       "      <td>100</td>\n",
       "      <td>802</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15296</th>\n",
       "      <td>100</td>\n",
       "      <td>1073</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>100</td>\n",
       "      <td>1356</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating\n",
       "15273     100        1     4.0\n",
       "15274     100        3     4.0\n",
       "15275     100        6     3.0\n",
       "15276     100        7     3.0\n",
       "15277     100       25     4.0\n",
       "15278     100       32     5.0\n",
       "15279     100       52     3.0\n",
       "15280     100       62     3.0\n",
       "15281     100       86     3.0\n",
       "15282     100       88     2.0\n",
       "15283     100       95     3.0\n",
       "15284     100      135     3.0\n",
       "15285     100      141     3.0\n",
       "15286     100      608     4.0\n",
       "15287     100      648     3.0\n",
       "15288     100      661     3.0\n",
       "15289     100      708     3.0\n",
       "15290     100      733     3.0\n",
       "15291     100      736     3.0\n",
       "15292     100      745     4.0\n",
       "15293     100      780     3.0\n",
       "15294     100      786     3.0\n",
       "15295     100      802     4.0\n",
       "15296     100     1073     5.0\n",
       "15297     100     1356     4.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.loc[ratings['userId']==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adventure', 'Comedy', 'Action', 'Thriller', 'Crime']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anita/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/anita/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/anita/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>wr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>[Drama, Crime]</td>\n",
       "      <td>8.344048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58559</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>[Drama, Action, Crime, Thriller]</td>\n",
       "      <td>8.201043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5618</th>\n",
       "      <td>Spirited Away</td>\n",
       "      <td>[Fantasy, Adventure, Animation, Family]</td>\n",
       "      <td>8.022190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79132</th>\n",
       "      <td>Inception</td>\n",
       "      <td>[Action, Thriller, Science Fiction, Mystery, A...</td>\n",
       "      <td>8.021702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109487</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>[Adventure, Drama, Science Fiction]</td>\n",
       "      <td>8.002558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>Life Is Beautiful</td>\n",
       "      <td>[Comedy, Drama]</td>\n",
       "      <td>8.001034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92259</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>[Drama, Comedy]</td>\n",
       "      <td>7.998925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>[Drama, Crime]</td>\n",
       "      <td>7.984395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>[Adventure, Fantasy, Action]</td>\n",
       "      <td>7.969959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Leon: The Professional</td>\n",
       "      <td>[Thriller, Crime, Drama]</td>\n",
       "      <td>7.953254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "movieId                                                  \n",
       "318                           The Shawshank Redemption   \n",
       "58559                                  The Dark Knight   \n",
       "5618                                     Spirited Away   \n",
       "79132                                        Inception   \n",
       "109487                                    Interstellar   \n",
       "2324                                 Life Is Beautiful   \n",
       "92259                                 The Intouchables   \n",
       "1221                            The Godfather: Part II   \n",
       "7153     The Lord of the Rings: The Return of the King   \n",
       "293                             Leon: The Professional   \n",
       "\n",
       "                                                    genres        wr  \n",
       "movieId                                                               \n",
       "318                                         [Drama, Crime]  8.344048  \n",
       "58559                     [Drama, Action, Crime, Thriller]  8.201043  \n",
       "5618               [Fantasy, Adventure, Animation, Family]  8.022190  \n",
       "79132    [Action, Thriller, Science Fiction, Mystery, A...  8.021702  \n",
       "109487                 [Adventure, Drama, Science Fiction]  8.002558  \n",
       "2324                                       [Comedy, Drama]  8.001034  \n",
       "92259                                      [Drama, Comedy]  7.998925  \n",
       "1221                                        [Drama, Crime]  7.984395  \n",
       "7153                          [Adventure, Fantasy, Action]  7.969959  \n",
       "293                               [Thriller, Crime, Drama]  7.953254  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pop.pref_genres(4))\n",
    "pop.recommend(4, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"> À blablater : méthode pas personalisée, privilégie les plus populaires et ne permet pas d'évaluer de manière quantitative la pertinence (pas de note)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering des films<a id='clustering'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la base de données et réduction de la matrice aux caractéristiques interéssantes\n",
    "\n",
    "Suppression des id incorrects, des valeurs abérrantes, des lignes avec NaN, et modification des valeurs pour les rendre plus faciles à traiter.\n",
    "\n",
    "On sélectionne les attributs de films qui semblent pertinents pour différencier les films sur leur contenu.\n",
    "Ces choix sont arbitraires et on pourra être amenés à réfléchir dessus et à les modifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ne voulons garder que les films ayant reçu une note. Cela est une manière de ne garder qu'un nombre limité de films (il est très compliqué pour nous d'effectuer des calculs pour 45 000 films). De plus le clustering est intéressant pour renforcer la recommendation \"user-based\". On ne garde donc que les films ayant été notés par les utilisateurs. Ensuite on rajoute l'attribut keywords aux films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_cluster = movies.join(link.set_index('tmdbId'), on='tmdbId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_cluster = dfm_cluster.merge(ratings.drop_duplicates('movieId'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_cluster = dfm_cluster.join(keywords.set_index('tmdbId'), on='tmdbId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>release_date</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>original_language</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>[{'id': 931, 'name': 'jealousy'}, {'id': 4290,...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>en</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>[{'id': 10090, 'name': 'board game'}, {'id': 1...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>en</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>[{'id': 1495, 'name': 'fishing'}, {'id': 12392...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>en</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>en</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>[{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n",
       "      <td>en</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "movieId                                \n",
       "1                          Toy Story   \n",
       "2                            Jumanji   \n",
       "3                   Grumpier Old Men   \n",
       "4                  Waiting to Exhale   \n",
       "5        Father of the Bride Part II   \n",
       "\n",
       "                                                    genres  \\\n",
       "movieId                                                      \n",
       "1        [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "2        [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "3        [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "4        [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "5                           [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                                                  keywords release_date  \\\n",
       "movieId                                                                   \n",
       "1        [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...   1995-10-30   \n",
       "2        [{'id': 10090, 'name': 'board game'}, {'id': 1...   1995-12-15   \n",
       "3        [{'id': 1495, 'name': 'fishing'}, {'id': 12392...   1995-12-22   \n",
       "4        [{'id': 818, 'name': 'based on novel'}, {'id':...   1995-12-22   \n",
       "5        [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n...   1995-02-10   \n",
       "\n",
       "                                      production_countries original_language  \\\n",
       "movieId                                                                        \n",
       "1        [{'iso_3166_1': 'US', 'name': 'United States o...                en   \n",
       "2        [{'iso_3166_1': 'US', 'name': 'United States o...                en   \n",
       "3        [{'iso_3166_1': 'US', 'name': 'United States o...                en   \n",
       "4        [{'iso_3166_1': 'US', 'name': 'United States o...                en   \n",
       "5        [{'iso_3166_1': 'US', 'name': 'United States o...                en   \n",
       "\n",
       "         runtime  \n",
       "movieId           \n",
       "1           81.0  \n",
       "2          104.0  \n",
       "3          101.0  \n",
       "4          127.0  \n",
       "5          106.0  "
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_id = dfm_cluster[['tmdbId','movieId','title']]\n",
    "cluster_features = dfm_cluster[['title', 'genres', 'keywords', 'release_date', 'production_countries', 'original_language', 'runtime']]\n",
    "cluster_features.index = dfm_cluster.movieId.apply(lambda x: str(x))\n",
    "cluster_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b39d0faec8>]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cluster_features.runtime.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On choisit de ne retenir que les films d'une durée comprise entre 40 minutes et 4 heures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_runtime(dfm, inf=40, sup=240):\n",
    "    dfm = dfm[dfm.runtime >= inf]\n",
    "    dfm = dfm[dfm.runtime <= sup]\n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_features = clean_runtime(cluster_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regarde la proportion de films pour lesquels certains champs n'ont pas été renseignés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de films retenus dans cluster_features :  8897\n",
      "Parmi ces films :\n",
      "30 n'ont pas de genres\n",
      "718 n'ont pas de keywords\n",
      "270 n'ont pas de production_countries\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de films retenus dans cluster_features : \", len(cluster_features))\n",
    "print(\"Parmi ces films :\")\n",
    "print(len(cluster_features[cluster_features.genres == \"[]\"]), \"n'ont pas de genres\")\n",
    "print(len(cluster_features[cluster_features.keywords == \"[]\"]), \"n'ont pas de keywords\")\n",
    "print(len(cluster_features[cluster_features.production_countries == \"[]\"]), \"n'ont pas de production_countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'une petite proportion, on peut donc retirer ces films problématiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_missing_values(dfm):\n",
    "    dfm = dfm[dfm.genres != \"[]\"]\n",
    "    dfm = dfm[dfm.keywords != \"[]\"]\n",
    "    dfm = dfm[dfm.production_countries != \"[]\"]\n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_features = drop_missing_values(cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de films dans cluster_features :  8037\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de films dans cluster_features : \", len(cluster_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant se concentrer sur le traitement des données de chacune des colonnes. Il faut les simplifier au maximum pour rendre possible la comparaison de films basée sur ces attributs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_genres(dfm):\n",
    "    \n",
    "    '''This function takes a DataFrame dfm that must contain a column 'genres'.\n",
    "    It turns the column genres from a string that contains a dictionnary into an int list of genres id.'''\n",
    "    \n",
    "    def genres_to_id(gen):\n",
    "        if isinstance(gen, str):\n",
    "            pattern = re.compile(r\"'id': [0-9]*\")\n",
    "            return np.array([int(w[6:]) for w in pattern.findall(gen)])\n",
    "        return gen\n",
    "    \n",
    "    dfm.genres = dfm.genres.apply(genres_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_genres(cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_keywords(dfm):\n",
    "    \n",
    "    '''This function takes a DataFrame dfm that must contain a column 'keywords'.\n",
    "    It turns the column keywords from a string that contains a dictionnary into an int list of keywords id.'''\n",
    "    \n",
    "    def keywords_to_id(kw):\n",
    "        if isinstance(kw, str):\n",
    "            pattern = re.compile(r\"'id': [0-9]*\")\n",
    "            return np.array([int(w[6:]) for w in pattern.findall(kw)])\n",
    "        return kw\n",
    "    \n",
    "    dfm.keywords = dfm.keywords.apply(keywords_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_keywords(cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_date(dfm):\n",
    "    \n",
    "    '''This function takes a DataFrame dfm that must contain a column 'release_date'.\n",
    "    It turns the column release_date from a string date into an int being the year the film was released.'''\n",
    "    \n",
    "    def date_to_int(date):\n",
    "        if isinstance(date, str):\n",
    "            return int(date[:4])\n",
    "        return date\n",
    "    \n",
    "    dfm.release_date = dfm.release_date.apply(date_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_date(cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_countries(dfm):\n",
    "    \n",
    "    '''This function takes a DataFrame dfm that must contain a column 'production_countries'.\n",
    "    It turns the column production_countries from a string that contains a dictionnary into an int list of keywords id.'''\n",
    "    \n",
    "    def simplify(country):\n",
    "        if isinstance(country, str):\n",
    "            pattern = re.compile(r\"'iso_3166_1': ...\")\n",
    "            return [w[15:] for w in pattern.findall(country)]\n",
    "        return country\n",
    "    \n",
    "    dfm.production_countries = dfm.production_countries.apply(simplify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_countries(cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>release_date</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>original_language</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[16, 35, 10751]</td>\n",
       "      <td>[931, 4290, 5202, 6054, 9713, 9823, 165503, 17...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[12, 14, 10751]</td>\n",
       "      <td>[10090, 10941, 15101, 33467, 158086, 158091]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[10749, 35]</td>\n",
       "      <td>[1495, 12392, 179431, 208510]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>[35, 18, 10749]</td>\n",
       "      <td>[818, 10131, 14768, 15160, 33455]</td>\n",
       "      <td>1995</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[1009, 1599, 2246, 4995, 5600, 10707, 13149, 3...</td>\n",
       "      <td>1995</td>\n",
       "      <td>[US]</td>\n",
       "      <td>en</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title           genres  \\\n",
       "movieId                                                 \n",
       "1                          Toy Story  [16, 35, 10751]   \n",
       "2                            Jumanji  [12, 14, 10751]   \n",
       "3                   Grumpier Old Men      [10749, 35]   \n",
       "4                  Waiting to Exhale  [35, 18, 10749]   \n",
       "5        Father of the Bride Part II             [35]   \n",
       "\n",
       "                                                  keywords  release_date  \\\n",
       "movieId                                                                    \n",
       "1        [931, 4290, 5202, 6054, 9713, 9823, 165503, 17...          1995   \n",
       "2             [10090, 10941, 15101, 33467, 158086, 158091]          1995   \n",
       "3                            [1495, 12392, 179431, 208510]          1995   \n",
       "4                        [818, 10131, 14768, 15160, 33455]          1995   \n",
       "5        [1009, 1599, 2246, 4995, 5600, 10707, 13149, 3...          1995   \n",
       "\n",
       "        production_countries original_language  runtime  \n",
       "movieId                                                  \n",
       "1                       [US]                en     81.0  \n",
       "2                       [US]                en    104.0  \n",
       "3                       [US]                en    101.0  \n",
       "4                       [US]                en    127.0  \n",
       "5                       [US]                en    106.0  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition d'une distance sur les films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va réaliser plus bas un hierarchical agglomerative clustering. Le principe est simple : on commence avec n clusters de 1 film, puis on fusionne à chaque itération les 2 clusters les plus proches, jusqu'à n'avoir plus d'un seul cluster contenant tous les films. Cela requiert une distance sur les films. C'est ce qu'on va construire ici. La tâche n'est pas simple : chaque film a été réduit à 7 attributs, et il faut aggréger ces 7 attributs pour déterminer à quel point 2 films sont similaires. On peut choisir d'accorder un poids différent à chacun des critères en fonction de leur importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit ici des variables globales qui seront utilisées plus loin dans la fonction movie_distance\n",
    "MAX_YEAR_DIFFERENCE = max(cluster_features.release_date) - min(cluster_features.release_date)\n",
    "MAX_RUNTIME_DIFFERENCE = max(cluster_features.runtime) - min(cluster_features.runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction movie_distance calcule une distance entre 2 films. Plus cette valeur est proches de 0 et plus les films sont similaires. Plus la valeur est grande et plus ils sont différents. IMPORTANT : la built-in magic command %lprun nous a permis d'analyser la répartition du temps d'exécution lors du clustering sur les données. 99% du temps de calcul réside dans cette fonction de distance. Ce qui est le plus coûteux en temps est l'accès aux attributs des films. On les a donc réduit au strict minimum. De plus, on ne créé pas de vecteur à 7 coefficients qui stockerait la similitude entre les 2 films pour chaque critère. A la place, on additionne directement le carré de ces valeurs dans une variable de somme, puis on renvoit la racine carrée de cette variable. On utilise la norme 2 en la calculant à la main pour accélérer les calculs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_distance(movie1, movie2, w_gen=4, w_key=2, w_rel=2, w_pro=3, w_ori=2, w_run=1):\n",
    "    \n",
    "    '''This function computes the distance between 2 movies m1 and m2 given some weight parameters.\n",
    "    It can be called either with 2 lists of attributes or with 2 movie Series, but the 2 parameters\n",
    "    must have the same type.'''\n",
    "    \n",
    "    assert type(movie1) is type(movie2)\n",
    "    sum_vect = 0 # avoiding to store a vector just to compute his norm afterwards\n",
    "    \n",
    "    if isinstance(movie1, pd.Series):\n",
    "        g1, g2 = movie1.genres, movie2.genres\n",
    "        kw1, kw2 = movie1.keywords, movie2.keywords\n",
    "        r1, r2 = movie1.release_date, movie2.release_date\n",
    "        pc1, pc2 = movie1.production_countries, movie2.production_countries\n",
    "        lang1, lang2 = movie1.original_language, movie2.original_language\n",
    "        run1, run2 = movie1.runtime, movie2.runtime\n",
    "    else:\n",
    "        # Access to both movie's attributes stored in the lists movie1 and movie2\n",
    "        g1, g2 = movie1[0], movie2[0]\n",
    "        kw1, kw2 = movie1[1], movie2[1]\n",
    "        r1, r2 = movie1[2], movie2[2]\n",
    "        pc1, pc2 = movie1[3], movie2[3]\n",
    "        lang1, lang2 = movie1[4], movie2[4]\n",
    "        run1, run2 = movie1[5], movie2[5]\n",
    "    \n",
    "    # SIMILARITIES IN GENRES\n",
    "    gen = np.append(g1, g2)\n",
    "    sum_vect += w_gen * (1 - (len(gen) - len(np.unique(gen))) / min(len(g1), len(g2))) ** 2\n",
    "    \n",
    "    # SIMILARITIES IN KEYWORDS\n",
    "    kw = np.append(kw1, kw2)\n",
    "    # Having one keyword in common is sufficient to make 2 films similar for this criterion\n",
    "    # This choice was made because most films have many keywords\n",
    "    if len(kw) == len(np.unique(kw)):\n",
    "        sum_vect += w_key * 1 # ** 2\n",
    "    \n",
    "    # SIMILARITIES FOR THE RELEASE DATE\n",
    "    # the normalized difference between the 2 releade dates\n",
    "    sum_vect += w_rel * (abs(r1 - r2) / MAX_YEAR_DIFFERENCE) ** 2\n",
    "    \n",
    "    # SIMILARITIES IN PRODUCTION COUNTRIES\n",
    "    pc = []\n",
    "    pc.extend(pc1)\n",
    "    pc.extend(pc2)\n",
    "    pc_dist = 1 - (len(pc) - len(np.unique(pc))) / min(len(pc1), len(pc2))\n",
    "    # As it is rare, we set that 2 films which are not from the US have something in common\n",
    "    if 'US' not in pc1 and 'US' not in pc2 and pc_dist > 0.5:\n",
    "        sum_vect += w_pro * 0.5 ** 2\n",
    "    else:\n",
    "        sum_vect += w_pro * pc_dist ** 2\n",
    "    \n",
    "    # SIMILARITIES FOR THE LANGUAGE\n",
    "    if lang1 != lang2 :\n",
    "        # As well, 2 films whose original language is not english have something in common\n",
    "        if lang1 != 'en' and lang2 != 'en':\n",
    "            sum_vect += w_ori * 0.5 ** 2\n",
    "        else:\n",
    "            sum_vect += w_ori * 1 ** 2\n",
    "    \n",
    "    # SIMILARITIES FOR THE RUNTIME\n",
    "    # the normalized difference between the 2 runtimes\n",
    "    sum_vect += w_run * (abs(run1 - run2) / MAX_RUNTIME_DIFFERENCE) ** 2\n",
    "    \n",
    "    return np.sqrt(sum_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant qu'on dispose d'une distance entre les films, on doit calculer la matrice de distance entre les films. Pour cela, on va utiliser un DataFrame avec en index et columns les id des movies (en string pour éviter toute confusion avec loc et iloc). On initilise un DataFrame vide avec les bonnes dimensions et les bons index / columns. On le remplit ensuite en faisant appel à la fonction movie_distance pour chaque paire de films. Comme par la suite on veut chercher le coefficient minimum de cette matrice, on met la distance d'un film à lui même à 1000 - un nombre suffisemment grand pour qu'aucune autre valeur de distance ne l'approche avec les choix de poids qu'on a fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist_matrix(clu_fea):\n",
    "    \n",
    "    '''This function computes the distance matrix between all the movies contained in clu_fea.\n",
    "    The clu_fea DataFrame must have been cleaned before. Returns the distance matrix.'''\n",
    "    \n",
    "    movies_id = clu_fea.index\n",
    "    dist_mat = pd.DataFrame(np.nan * len(clu_fea), index=movies_id, columns=movies_id)\n",
    "    \n",
    "    # Faire des .loc / .iloc sur un DataFrame prend enormement de temps. Pour eviter cela,\n",
    "    # on le fait pour chaque attribut de chaque film une bonne fois pour toutes, et on stocke\n",
    "    # cela dans une matrice. On est forcé d'utiliser une double liste python car chaque element\n",
    "    # de la matrice peut etre de type int, float, str ou encore list. C'est envrion 4 fois plus\n",
    "    # rapide que de rester avec un DataFrame en accédant aux attributs des films !\n",
    "    \n",
    "    mat_mem = []\n",
    "    for i in range(len(clu_fea)):\n",
    "        mov_i = clu_fea.iloc[i]\n",
    "        mat_mem.append([mov_i.genres, mov_i.keywords, mov_i.release_date,\n",
    "                     mov_i.production_countries, mov_i.original_language, mov_i.runtime])\n",
    "    \n",
    "    # On peut maintenant calculer la distance entre chaque paire de films\n",
    "    # La distance d'un film avec lui meme est fixee a 1000 par defaut\n",
    "    # pour eviter de fusionner un cluster avec lui meme\n",
    "    \n",
    "    for i in range(len(clu_fea)):\n",
    "        for j in range(i, len(clu_fea)):\n",
    "            if i == j:\n",
    "                dist_mat.iat[i, j] = 1000\n",
    "            else:\n",
    "                dist_mat.iat[i, j] = dist_mat.iat[j, i] = movie_distance(mat_mem[i], mat_mem[j])\n",
    "    \n",
    "    return dist_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HIERARCHICAL AGGLOMERATIVE CLUSTERING </b> <br>\n",
    "Dans ce type de méthode de clustering, on n'a pas besoin de préciser le nombre de clusters attendus. L'algorithme permet de construire un dendrogramme, et on obtient nos clusters en coupant le dendrogramme à une certaine hauteur. On va commencer par écrire une classe Dendrogram. Un objet de cette classe contient plusieurs attributs :\n",
    "<li>Un champ leaf - valant None pour les noeuds dans l'arbre et contenant l'id d'un film (int) pour les feuilles </li>\n",
    "<li>Un champ leaf_nb - un int indiquant pour chaque noeud le nombre de feuilles (et donc de films) de l'abre issu de ce noeud </li>\n",
    "<li>Un champ father - une référence vers le père du noeud </li>\n",
    "<li>Un champ left et un champ right - une référence vers le fils gauche (resp. fils droit) du noeud </li>\n",
    "<li>Un champ height - un float indiquant la hauteur du noeud. Attention ! Il ne s'agit pas de la notion classique de hauteur d'un noeud dans un arbre binaire. <br>Il s'agit ici de la hauteur de fusion entre les 2 groupes de films (fils gauche et fils droit). Plus elle est élevée et plus ces 2 groupes de films sont différents </li>\n",
    "<li>Un champ distance_to_father - un float indiquant la longueur de l'arête reliant le noeud à son père </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dendrogram:\n",
    "    \n",
    "    def __init__(self, leaf=None):\n",
    "        \n",
    "        '''This is the Dendrogram class constructor. It takes only one optional argument, which is leaf if the user\n",
    "        wants to build a leaf containing a movie id. Otherwise it is a node and the leaf attribute is set to None.\n",
    "        The other attributes are set to 0 or None for now, and should be modified by setters later on.'''\n",
    "        \n",
    "        self.leaf = leaf\n",
    "        self.leaf_nb = 1\n",
    "        self.father = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.height = 0\n",
    "        self.distance_to_father = 0\n",
    "    \n",
    "    def set_leaf_nb(self):\n",
    "        \n",
    "        '''This method is a setter for the leaf_nb attribute. It requires the left and right sons, as the total number\n",
    "        of leaves of the node is the sum of its left and right leaf_nb attributes. If called on a leaf, leaf_nb should\n",
    "        equal 1 due to the constructor, and set_leaf_nb set leaf_nb to 1 as well. This methode should always be called\n",
    "        after creating a node that is not a leaf.'''\n",
    "        \n",
    "        total_leaf_nb = 0\n",
    "        if self.left is not None:\n",
    "            total_leaf_nb += self.left.leaf_nb\n",
    "        if self.right is not None:\n",
    "            total_leaf_nb += self.right.leaf_nb\n",
    "        self.leaf_nb = max(1, total_leaf_nb)\n",
    "    \n",
    "    def set_height(self, height):\n",
    "        \n",
    "        '''This method is a setter for the height attribute. The height is given as a parameter. This method also sets\n",
    "        the distance_to_father attribute of the node's left and right sons. If called on a leaf, this method does nothing.\n",
    "        This methode should always be called after creating a node that is not a leaf.'''\n",
    "        \n",
    "        if self.left is None or self.right is None:\n",
    "            return\n",
    "        self.height = height\n",
    "        self.left.distance_to_father = height - self.left.height\n",
    "        self.right.distance_to_father = height - self.right.height\n",
    "    \n",
    "    def get_id_list(self):\n",
    "        \n",
    "        '''This method returns a list of all the id contained in the leafs of the node.It uses a prefix run.'''\n",
    "        \n",
    "        id_list = []\n",
    "        def prefix(node):\n",
    "            if node.leaf is not None:\n",
    "                id_list.append(node.leaf)\n",
    "            else:\n",
    "                prefix(node.right)\n",
    "                prefix(node.left)\n",
    "        prefix(self)\n",
    "        \n",
    "        return id_list\n",
    "    \n",
    "    def get_root(self):\n",
    "        \n",
    "        '''This method returns the root of the tree to which the node belongs. The main goal of this method is\n",
    "        to start from a leaf and find the root of the dendrogram, which is the leaf's cluster at a step k.'''\n",
    "        \n",
    "        tmp = self\n",
    "        while tmp.father is not None: tmp = tmp.father\n",
    "        return tmp\n",
    "    \n",
    "    def cut_at_threshold(self, threshold):\n",
    "        \n",
    "        '''This method provides a cut of the dendrogram at a height given by parameter threshold. It returns a list\n",
    "        of Dendrogram objects. Each element of the list can be seen as the root of a dendrogram, i.e. a cluster.'''\n",
    "        \n",
    "        assert threshold >= 0\n",
    "        assert threshold <= self.height\n",
    "        node_list = []\n",
    "        def step(node, t):\n",
    "            if node.height == 0:\n",
    "                node_list.append([node])\n",
    "            else:\n",
    "                if node.left.height <= t:\n",
    "                    node_list.append(node.left)\n",
    "                else:\n",
    "                    step(node.left, t)\n",
    "                if node.right.height <= t:\n",
    "                    node_list.append(node.right)\n",
    "                else:\n",
    "                    step(node.right, t)\n",
    "        step(self, threshold)\n",
    "        \n",
    "        return node_list\n",
    "    \n",
    "    def clusters_threshold_cut(self, threshold):\n",
    "        \n",
    "        '''This method uses cut_at_threshold in order to return a list of movies id list. Each element\n",
    "        of the list is a cluster that directly contains the id of all movies that belong to the cluster.'''\n",
    "        \n",
    "        cluster_list = self.cut_at_threshold(threshold)\n",
    "        return [node.get_id_list() for node in cluster_list]\n",
    "    \n",
    "    def find_best_cut(self):\n",
    "        \n",
    "        '''This method does dendrogram cuts at 200 different threshold and keeps the best cut. It returns a list of\n",
    "        movies id list, i.e. the different clusters. Some changes had to be made to avoid getting too many clusters.\n",
    "        This is due to the distance choice between movies. Some attributes such as director or keywords are almost\n",
    "        all different for 2 movies, resulting in a high distance between most movies, even between 2 movies that are\n",
    "        very similar regarding genres, language, release date, production countries and runtime. That is why the method\n",
    "        imposes a maximum number of clusters, which depends on the size of the input. The upper bound is quite high so\n",
    "        that it enables many clusters, and it avoids to have some situations with e.g. 100 movies and 43 clusters.'''\n",
    "        \n",
    "        max_clu_nb = self.leaf_nb / np.sqrt(self.leaf_nb)\n",
    "        threshold_list = np.linspace(0.01, self.height, 200)\n",
    "        def step(t):\n",
    "            nodes = self.cut_at_threshold(t)\n",
    "            if len(nodes) > max_clu_nb:\n",
    "                return 0\n",
    "            return sum([n.distance_to_father for n in nodes]) / len(nodes)\n",
    "        score = [step(t) for t in threshold_list]\n",
    "        best_threshold_index = np.argmax(score)\n",
    "        best_threshold = threshold_list[best_threshold_index]\n",
    "        \n",
    "        return self.clusters_threshold_cut(best_threshold)\n",
    "    \n",
    "    def get_n_clusters(self, n):\n",
    "        \n",
    "        '''This method provides a cut on the dendrogram that gives a number n of clusters, chosen in parameter.\n",
    "        The different clusters are obtained by cutting at a threshold that leads to n clusters.\n",
    "        It uses dichotomy in order to be efficient. It tries a cut at mid-height, check the number of\n",
    "        clusters obtained and then decides to stop, cut at a higher height or cut at a lower height.'''\n",
    "        \n",
    "        assert n >= 1\n",
    "        assert n <= self.leaf_nb\n",
    "        # dichotomy\n",
    "        xmin, xmax, xmid = 0, self.height, self.height / 2\n",
    "        nodes = self.cut_at_threshold(xmid)\n",
    "        while len(nodes) != n:\n",
    "            if len(nodes) < n: \n",
    "                xmax, xmid = xmid, (xmid + xmin) / 2\n",
    "            else:\n",
    "                xmin, xmid = xmid, (xmid + xmax) / 2\n",
    "            nodes = self.cut_at_threshold(xmid)\n",
    "            # if the loop does not end - extremely unlickely but not impossible if 2 nodes\n",
    "            # have the same height - it calls another cut function that returns n clusters\n",
    "            if xmax - xmin < 1e-5:\n",
    "                return self.get_n_clusters_perso(n)[0]\n",
    "        \n",
    "        return [n.get_id_list() for n in nodes]\n",
    "        \n",
    "    def get_n_clusters_perso(self, n):\n",
    "        \n",
    "        '''This method provides a cut on the dendrogram that gives a number n of clusters, chosen in parameter.\n",
    "        It is called get_n_clusters_perso because I imaginated it alone and I don't think it exists elsewhere.\n",
    "        The goal of this method is to solve the following problem : most of the time, cutting a dendrogram at\n",
    "        a given height leads to a certain number of clusters. Among these clusters, some can be very small, there\n",
    "        are even clusters with one element. So, instead of cutting at a threshold, the idea of this method is the\n",
    "        following : it starts at the root and must provide n clusters, e.g. let's take n=10. If the left son's leaf\n",
    "        number is greater than the right son's one, then the left son must provide let's say n=7 clusters, while the\n",
    "        right son must provide n=3 clusters. Finally if the right son's have a very small number of leaves compared\n",
    "        to the left son's one, then the left son must provide n=10 clusters and the leaves of the right son are added\n",
    "        to a list of outliers. At the end of the process, there will be 10 clusters quite well balanced and one list\n",
    "        of outliers, which can form a special cluster of, let's say, unclassifiable movies.'''\n",
    "        \n",
    "        if n <= 0 or n > self.leaf_nb:\n",
    "            print(\"Bad choice for n : too big or <= 0\")\n",
    "            return\n",
    "        cluster_list = []\n",
    "        outliers = []\n",
    "        error = []\n",
    "        def step(node, n):\n",
    "            if n == 1:\n",
    "                cluster_list.append(node.get_id_list())\n",
    "            elif node.left is None or node.right is None:\n",
    "                error.append(True)\n",
    "            else:\n",
    "                prop_left = node.left.leaf_nb / node.leaf_nb\n",
    "                prop_right = node.right.leaf_nb / node.leaf_nb\n",
    "                # a node is considered an outlier if his leaf number\n",
    "                # is less than 15% of his father's leaf number\n",
    "                if prop_left < 0.15:\n",
    "                    outliers.extend(node.left.get_id_list())\n",
    "                    step(node.right, n)\n",
    "                elif prop_right < 0.15:\n",
    "                    outliers.extend(node.right.get_id_list())\n",
    "                    step(node.left, n)\n",
    "                else:\n",
    "                    n_left = max(1, round(n * prop_left))\n",
    "                    if n_left == n:\n",
    "                        n_left -= 1\n",
    "                    n_right = n - n_left\n",
    "                    step(node.left, n_left)\n",
    "                    step(node.right, n_right)\n",
    "        step(self, n)\n",
    "        if error:\n",
    "            print(\"n too big\")\n",
    "        else:\n",
    "            return cluster_list, outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut désormais écrire une classe pour implémenter le Hierarchical Agglomerative Clustering. Un objet de cette classe contiendra les attributs suivants :<br>\n",
    "<li>Un champ dendrogram_root - une référence vers la racine du dendrogramme</li>\n",
    "<li>Un champ cluster_id_list - une liste de listes de movies id, i.e. la liste des clusters</li>\n",
    "<li>Un champ outliers - une liste de movies id, existant uniquement si on choisi la méthode perso</li>\n",
    "<li>Un champ cluster_features - le DataFrame des films nettoyé sur lequel on apprend </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalCluster:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        '''This is the HierarchicalCluster class constructor. It takes no arguments, all it does is to\n",
    "        build an object. The 4 attributes will be initialized later on, when training the model.'''\n",
    "        \n",
    "        self.dendrogram_root = None\n",
    "        self.cluster_id_list = None\n",
    "        self.outliers = None\n",
    "        self.cluster_features = None\n",
    "    \n",
    "    def set_cluster_features(self, dfm):\n",
    "        \n",
    "        '''This method is a setter for the attribute cluster_features. It takes one parameter, dfm, which is\n",
    "        a DataFrame that contains all the information about movies. The method cleans the DataFrame and keeps\n",
    "        only the attributes that are relevant for the movie clustering.'''\n",
    "        \n",
    "        # selection des attributs qui nous interessent pour le clustering\n",
    "        clu_fea = dfm[['genres','keywords','release_date','production_countries','original_language','runtime']]\n",
    "        # on met en index les id des movies\n",
    "        clu_fea.index = dfm.movieId.apply(lambda x: str(x))\n",
    "        # nettoyage du dataframe\n",
    "        clu_fea = clean_runtime(clu_fea)\n",
    "        clu_fea = drop_missing_values(clu_fea)\n",
    "        vectorize_keywords(clu_fea)\n",
    "        vectorize_genres(clu_fea)\n",
    "        simplify_date(clu_fea)\n",
    "        simplify_countries(clu_fea)\n",
    "        self.cluster_features = clu_fea\n",
    "    \n",
    "    def agglomerative_cluster(self, dist_mat):\n",
    "        \n",
    "        '''This method builds a dendrogram based on the distance matrix given in parameters. It returns\n",
    "        its root. Important things to know about this function : 1) In order to avoid redundancy and to make\n",
    "        the computations faster, it reduces the matrix size at each step by dropping a row and a colums.\n",
    "        At the end, the matrix has 1x1 shape, so if one wants to store the matrix and keep it unchanged,\n",
    "        he must call this method with a copy. 2) A choice which has a huge impact on the dendrogram was made\n",
    "        here. In the algorithm, the 2 closest clusters are merged into a bigger one at each step. But there are\n",
    "        several ways to measure the distance between clusters. It can be the distance between the centroids, the\n",
    "        average distance, the minimal or maximal distance bewteen 2 points from different clusters. We chose this\n",
    "        last option. It avoids to have many unbalanced branches, especially at levels close to the root.'''\n",
    "        \n",
    "        assert self.cluster_features is not None\n",
    "        clu_fea = self.cluster_features\n",
    "        clu_fea[\"dendrogram\"] = clu_fea.index\n",
    "        clu_fea.dendrogram = clu_fea.dendrogram.apply(lambda x: Dendrogram(leaf=int(x)))\n",
    "        size_mat = len(clu_fea)\n",
    "        for _ in range(1, size_mat):\n",
    "            # localisation de la plus petite distance dans la matrice\n",
    "            index_str1, index_str2 = dist_mat.stack().idxmin()\n",
    "            height = dist_mat.loc[index_str1, index_str2]\n",
    "            mov1 = clu_fea.loc[index_str1]\n",
    "            mov2 = clu_fea.loc[index_str2]\n",
    "            tmp1 = mov1.dendrogram\n",
    "            tmp2 = mov2.dendrogram\n",
    "            # acces a la racine du cluster de mov1 et de celui de mov2\n",
    "            while tmp1.father is not None: tmp1 = tmp1.father\n",
    "            while tmp2.father is not None: tmp2 = tmp2.father\n",
    "            # creation de la racine du nouvel arbre, fusion des 2 clusters\n",
    "            tmp3 = Dendrogram()\n",
    "            tmp3.left = tmp1\n",
    "            tmp3.right = tmp2\n",
    "            tmp1.father = tmp3\n",
    "            tmp2.father = tmp3\n",
    "            tmp3.set_leaf_nb()\n",
    "            tmp3.set_height(height)\n",
    "            # actualisation de la matrice de distance\n",
    "            new_d = np.maximum(dist_mat.loc[index_str1, :], dist_mat.loc[index_str2, :])\n",
    "            dist_mat.loc[index_str1, :] = dist_mat.loc[:, index_str1] = new_d\n",
    "            # suppression d'une des 2 lignes et colonnes qui font maintenant doublons\n",
    "            dist_mat = dist_mat.drop(index_str2, axis=0)\n",
    "            dist_mat = dist_mat.drop(index_str2, axis=1)\n",
    "        \n",
    "        return clu_fea.iloc[0].dendrogram.get_root()\n",
    "    \n",
    "    def train(self, dfm_cluster):\n",
    "        \n",
    "        '''This method coordinates the cluster construction. Firstly it cleans the DataFrame by calling the\n",
    "        set_cluster_features method. Then it calls the function that computes the distance matrix. Finally\n",
    "        it calls the agglomerative_cluster method in order to build the dendrogram.'''\n",
    "        \n",
    "        self.set_cluster_features(dfm_cluster)\n",
    "        dist_mat = compute_dist_matrix(self.cluster_features)\n",
    "        self.dendrogram_root = self.agglomerative_cluster(dist_mat)\n",
    "    \n",
    "    def set_n_clusters(self, n):\n",
    "        \n",
    "        '''This method cuts the dendrogram at a height that forms n different clusters.'''\n",
    "        \n",
    "        if self.dendrogram_root is None:\n",
    "            print(\"Erreur, vous devez d'abord construire le dendrogram avec la methode train.\")\n",
    "        else:\n",
    "            self.outliers = None\n",
    "            self.cluster_id_list = self.dendrogram_root.get_n_clusters(n)\n",
    "    \n",
    "    def set_best_n_clusters(self):\n",
    "        \n",
    "        '''This method cuts the dendrogram at a height that maximizes the distance_to_father attributes\n",
    "        of the cluster roots, on the condition that it doesn't create too many clusters.'''\n",
    "        \n",
    "        if self.dendrogram_root is None:\n",
    "            print(\"Erreur, vous devez d'abord construire le dendrogram avec la methode train.\")\n",
    "        else:\n",
    "            self.cluster_id_list = self.dendrogram_root.find_best_cut()\n",
    "    \n",
    "    def set_n_clusters_perso(self, n):\n",
    "        \n",
    "        '''This method cuts the dendrogram at different heights depending on the branch, so that if forms\n",
    "        n clusters quite well balanced. It does not take the nodes height in consideration.'''\n",
    "        \n",
    "        if self.dendrogram_root is None:\n",
    "            print(\"Erreur, vous devez d'abord construire le dendrogram avec la methode train.\")\n",
    "        else:\n",
    "            self.cluster_id_list, self.outliers = self.dendrogram_root.get_n_clusters_perso(n)\n",
    "    \n",
    "    def get_cluster(self, pos, movies=None):\n",
    "        \n",
    "        '''This method returns a DataFrame that contains the movies from cluster number pos (first pos is 1).\n",
    "        It uses the self.cluster_features attribute if the argument movies is not precised.'''\n",
    "        \n",
    "        if movies is None:\n",
    "            movies = self.cluster_features\n",
    "        if pos <= 0:\n",
    "            print(\"Erreur, l'argument doit etre >= 1\")\n",
    "            return\n",
    "        if pos > len(self.cluster_id_list):\n",
    "            print(\"Erreur, il y a seulement \", len(self.cluster_id_list), \" clusters.\")\n",
    "            return\n",
    "        if self.cluster_id_list is None:\n",
    "            print(\"Erreur, vous devez d'abord choisir un nombre de clusters avec la methode set_n_clusters.\")\n",
    "            return\n",
    "        df = pd.DataFrame([])\n",
    "        if 'movieId' in movies.columns:\n",
    "            for i in self.cluster_id_list[pos - 1]:\n",
    "                df = df.append(movies[movies.movieId == int(i)])\n",
    "        else:\n",
    "            for i in self.cluster_id_list[pos - 1]:\n",
    "                df = df.append(movies.loc[str(i)])\n",
    "        return df\n",
    "    \n",
    "    def get_outliers(self, movies=None):\n",
    "        \n",
    "        '''This method returns a DataFrame that contains all the outliers movies. It exists only if the perso\n",
    "        method is used when setting a number of clusters. Otherwise it returns an empty DataFrame.'''\n",
    "        \n",
    "        df = pd.DataFrame([])\n",
    "        if self.outliers is None:\n",
    "            return df\n",
    "        if movies is None:\n",
    "            movies = self.cluster_features\n",
    "        if 'movieId' in movies.columns:\n",
    "            for i in outliers:\n",
    "                df = df.append(movies[movies.movieId == int(i)])\n",
    "        else:\n",
    "            for i in outliers:\n",
    "                df = df.append(movies.loc[str(i)])\n",
    "        return df\n",
    "    \n",
    "    def get_clusters_size(self):\n",
    "        \n",
    "        '''This method returns a list containing the size of the clusters,\n",
    "        i.e. the number of movies for each cluster.'''\n",
    "        \n",
    "        if self.cluster_id_list is None:\n",
    "            print(\"Erreur, vous devez d'abord choisir un nombre de clusters avec la methode set_n_clusters.\")\n",
    "            return\n",
    "        l = []\n",
    "        for id_list in self.cluster_id_list:\n",
    "            l.append(len(id_list))\n",
    "        return l\n",
    "    \n",
    "    def find_closest_cluster(self, movie):\n",
    "        \n",
    "        '''This method finds the closest cluster for a movie given in parameter. The closest cluster is the\n",
    "        cluster that contains the movie that is the closest to the argument.'''\n",
    "        \n",
    "        if self.cluster_id_list is None:\n",
    "            print(\"Erreur, vous devez d'abord choisir un nombre de clusters avec la methode set_n_clusters.\")\n",
    "            return\n",
    "        min_list = []\n",
    "        for cluster in self.cluster_id_list:\n",
    "            min_dist = np.min([movie_distance(movie, self.cluster_features.loc[str(m)]) for m in cluster])\n",
    "            min_list.append(min_dist)\n",
    "        index_closest_cluser = np.argmin(min_list)\n",
    "        \n",
    "        return self.cluster_id_list[index_closest_cluser]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sur un échantillon de taille 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_10 = HierarchicalCluster()\n",
    "test_10 = dfm_cluster.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28 ms\n"
     ]
    }
   ],
   "source": [
    "%time cluster_10.train(test_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_10.set_n_clusters(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1019</td>\n",
       "      <td>[12, 18, 878]</td>\n",
       "      <td>[269, 270, 339, 385, 1316, 2768, 2769, 2770, 2...</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>20,000 Leagues Under the Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4211</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[5565]</td>\n",
       "      <td>en</td>\n",
       "      <td>[JP, GB, US]</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Reversal of Fortune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genres                                           keywords  \\\n",
       "1019  [12, 18, 878]  [269, 270, 339, 385, 1316, 2768, 2769, 2770, 2...   \n",
       "4211           [18]                                             [5565]   \n",
       "\n",
       "     original_language production_countries  release_date  runtime  \\\n",
       "1019                en                 [US]        1954.0    127.0   \n",
       "4211                en         [JP, GB, US]        1990.0    111.0   \n",
       "\n",
       "                             title  \n",
       "1019  20,000 Leagues Under the Sea  \n",
       "4211           Reversal of Fortune  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(1, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>93287</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[720, 818, 2676, 3800, 18006, 18007, 179431]</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>The Big Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7827</td>\n",
       "      <td>[53, 878, 9648]</td>\n",
       "      <td>[848, 1568, 2251, 4183, 6129, 6133, 9016, 1041...</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Cypher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                genres                                           keywords  \\\n",
       "93287             [35]       [720, 818, 2676, 3800, 18006, 18007, 179431]   \n",
       "7827   [53, 878, 9648]  [848, 1568, 2251, 4183, 6129, 6133, 9016, 1041...   \n",
       "\n",
       "      original_language production_countries  release_date  runtime  \\\n",
       "93287                en                 [US]        2011.0    100.0   \n",
       "7827                 en                 [US]        2002.0     95.0   \n",
       "\n",
       "              title  \n",
       "93287  The Big Year  \n",
       "7827         Cypher  "
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(2, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25995</td>\n",
       "      <td>[18, 28, 12]</td>\n",
       "      <td>[907, 1462, 11020]</td>\n",
       "      <td>ja</td>\n",
       "      <td>[JP]</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Samurai I: Musashi Miyamoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>[18, 36]</td>\n",
       "      <td>[3686, 8846, 9920, 10089]</td>\n",
       "      <td>fr</td>\n",
       "      <td>[FR, DE, IT]</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Queen Margot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65037</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[240, 1850, 2486, 3026, 3698, 3851, 4563, 6186...</td>\n",
       "      <td>nl</td>\n",
       "      <td>[BE]</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Ben X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genres                                           keywords  \\\n",
       "25995  [18, 28, 12]                                 [907, 1462, 11020]   \n",
       "302        [18, 36]                          [3686, 8846, 9920, 10089]   \n",
       "65037          [18]  [240, 1850, 2486, 3026, 3698, 3851, 4563, 6186...   \n",
       "\n",
       "      original_language production_countries  release_date  runtime  \\\n",
       "25995                ja                 [JP]        1954.0     93.0   \n",
       "302                  fr         [FR, DE, IT]        1994.0    162.0   \n",
       "65037                nl                 [BE]        2007.0     90.0   \n",
       "\n",
       "                             title  \n",
       "25995  Samurai I: Musashi Miyamoto  \n",
       "302                   Queen Margot  \n",
       "65037                        Ben X  "
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(3, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_10.set_n_clusters_perso(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1019</td>\n",
       "      <td>[12, 18, 878]</td>\n",
       "      <td>[269, 270, 339, 385, 1316, 2768, 2769, 2770, 2...</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>20,000 Leagues Under the Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4211</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[5565]</td>\n",
       "      <td>en</td>\n",
       "      <td>[JP, GB, US]</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Reversal of Fortune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genres                                           keywords  \\\n",
       "1019  [12, 18, 878]  [269, 270, 339, 385, 1316, 2768, 2769, 2770, 2...   \n",
       "4211           [18]                                             [5565]   \n",
       "\n",
       "     original_language production_countries  release_date  runtime  \\\n",
       "1019                en                 [US]        1954.0    127.0   \n",
       "4211                en         [JP, GB, US]        1990.0    111.0   \n",
       "\n",
       "                             title  \n",
       "1019  20,000 Leagues Under the Sea  \n",
       "4211           Reversal of Fortune  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(1, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>93287</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[720, 818, 2676, 3800, 18006, 18007, 179431]</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>The Big Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7827</td>\n",
       "      <td>[53, 878, 9648]</td>\n",
       "      <td>[848, 1568, 2251, 4183, 6129, 6133, 9016, 1041...</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Cypher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                genres                                           keywords  \\\n",
       "93287             [35]       [720, 818, 2676, 3800, 18006, 18007, 179431]   \n",
       "7827   [53, 878, 9648]  [848, 1568, 2251, 4183, 6129, 6133, 9016, 1041...   \n",
       "\n",
       "      original_language production_countries  release_date  runtime  \\\n",
       "93287                en                 [US]        2011.0    100.0   \n",
       "7827                 en                 [US]        2002.0     95.0   \n",
       "\n",
       "              title  \n",
       "93287  The Big Year  \n",
       "7827         Cypher  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(2, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25995</td>\n",
       "      <td>[18, 28, 12]</td>\n",
       "      <td>[907, 1462, 11020]</td>\n",
       "      <td>ja</td>\n",
       "      <td>[JP]</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Samurai I: Musashi Miyamoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>[18, 36]</td>\n",
       "      <td>[3686, 8846, 9920, 10089]</td>\n",
       "      <td>fr</td>\n",
       "      <td>[FR, DE, IT]</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Queen Margot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65037</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[240, 1850, 2486, 3026, 3698, 3851, 4563, 6186...</td>\n",
       "      <td>nl</td>\n",
       "      <td>[BE]</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Ben X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genres                                           keywords  \\\n",
       "25995  [18, 28, 12]                                 [907, 1462, 11020]   \n",
       "302        [18, 36]                          [3686, 8846, 9920, 10089]   \n",
       "65037          [18]  [240, 1850, 2486, 3026, 3698, 3851, 4563, 6186...   \n",
       "\n",
       "      original_language production_countries  release_date  runtime  \\\n",
       "25995                ja                 [JP]        1954.0     93.0   \n",
       "302                  fr         [FR, DE, IT]        1994.0    162.0   \n",
       "65037                nl                 [BE]        2007.0     90.0   \n",
       "\n",
       "                             title  \n",
       "25995  Samurai I: Musashi Miyamoto  \n",
       "302                   Queen Margot  \n",
       "65037                        Ben X  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(3, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_10.set_best_n_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>93287</td>\n",
       "      <td>[35]</td>\n",
       "      <td>[720, 818, 2676, 3800, 18006, 18007, 179431]</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>The Big Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7827</td>\n",
       "      <td>[53, 878, 9648]</td>\n",
       "      <td>[848, 1568, 2251, 4183, 6129, 6133, 9016, 1041...</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Cypher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1019</td>\n",
       "      <td>[12, 18, 878]</td>\n",
       "      <td>[269, 270, 339, 385, 1316, 2768, 2769, 2770, 2...</td>\n",
       "      <td>en</td>\n",
       "      <td>[US]</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>20,000 Leagues Under the Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4211</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[5565]</td>\n",
       "      <td>en</td>\n",
       "      <td>[JP, GB, US]</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>Reversal of Fortune</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                genres                                           keywords  \\\n",
       "93287             [35]       [720, 818, 2676, 3800, 18006, 18007, 179431]   \n",
       "7827   [53, 878, 9648]  [848, 1568, 2251, 4183, 6129, 6133, 9016, 1041...   \n",
       "1019     [12, 18, 878]  [269, 270, 339, 385, 1316, 2768, 2769, 2770, 2...   \n",
       "4211              [18]                                             [5565]   \n",
       "\n",
       "      original_language production_countries  release_date  runtime  \\\n",
       "93287                en                 [US]        2011.0    100.0   \n",
       "7827                 en                 [US]        2002.0     95.0   \n",
       "1019                 en                 [US]        1954.0    127.0   \n",
       "4211                 en         [JP, GB, US]        1990.0    111.0   \n",
       "\n",
       "                              title  \n",
       "93287                  The Big Year  \n",
       "7827                         Cypher  \n",
       "1019   20,000 Leagues Under the Sea  \n",
       "4211            Reversal of Fortune  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(1, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25995</td>\n",
       "      <td>[18, 28, 12]</td>\n",
       "      <td>[907, 1462, 11020]</td>\n",
       "      <td>ja</td>\n",
       "      <td>[JP]</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Samurai I: Musashi Miyamoto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>[18, 36]</td>\n",
       "      <td>[3686, 8846, 9920, 10089]</td>\n",
       "      <td>fr</td>\n",
       "      <td>[FR, DE, IT]</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Queen Margot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65037</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[240, 1850, 2486, 3026, 3698, 3851, 4563, 6186...</td>\n",
       "      <td>nl</td>\n",
       "      <td>[BE]</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Ben X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             genres                                           keywords  \\\n",
       "25995  [18, 28, 12]                                 [907, 1462, 11020]   \n",
       "302        [18, 36]                          [3686, 8846, 9920, 10089]   \n",
       "65037          [18]  [240, 1850, 2486, 3026, 3698, 3851, 4563, 6186...   \n",
       "\n",
       "      original_language production_countries  release_date  runtime  \\\n",
       "25995                ja                 [JP]        1954.0     93.0   \n",
       "302                  fr         [FR, DE, IT]        1994.0    162.0   \n",
       "65037                nl                 [BE]        2007.0     90.0   \n",
       "\n",
       "                             title  \n",
       "25995  Samurai I: Musashi Miyamoto  \n",
       "302                   Queen Margot  \n",
       "65037                        Ben X  "
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_10.get_cluster(2, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur, il y a seulement  2  clusters.\n"
     ]
    }
   ],
   "source": [
    "cluster_10.get_cluster(3, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur, il y a seulement  2  clusters.\n"
     ]
    }
   ],
   "source": [
    "cluster_10.get_cluster(4, cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur, il y a seulement  2  clusters.\n"
     ]
    }
   ],
   "source": [
    "cluster_10.get_cluster(5, cluster_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test sur un échantillon de taille 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_100 = dfm_cluster.sample(100)\n",
    "cluster_100 = HierarchicalCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 430 ms\n"
     ]
    }
   ],
   "source": [
    "%time cluster_100.train(test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f movie_distance cluster_100.train(test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 2, 2, 38, 29, 2]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_100.set_n_clusters(6)\n",
    "cluster_100.get_clusters_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  outliers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15, 16, 4, 16, 21, 8]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_100.set_n_clusters_perso(6)\n",
    "print(len(cluster_100.outliers), \" outliers\")\n",
    "cluster_100.get_clusters_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 2, 2, 22, 16, 21, 8, 2]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_100.set_best_n_clusters()\n",
    "cluster_100.get_clusters_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données complètes : 119 minutes pour run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = HierarchicalCluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 59min 1s\n"
     ]
    }
   ],
   "source": [
    "%time cluster.train(dfm_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3345, 1945, 939, 270, 260, 503, 23, 189, 20, 543]"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.set_n_clusters(10)\n",
    "cluster.get_clusters_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  outliers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1044, 522, 1293, 387, 968, 182, 746, 939, 995, 543]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.set_n_clusters_perso(10)\n",
    "print(len(cluster_100.outliers), \" outliers\")\n",
    "cluster.get_clusters_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1566,\n",
       " 1684,\n",
       " 95,\n",
       " 1945,\n",
       " 253,\n",
       " 80,\n",
       " 356,\n",
       " 9,\n",
       " 30,\n",
       " 46,\n",
       " 12,\n",
       " 23,\n",
       " 70,\n",
       " 60,\n",
       " 249,\n",
       " 21,\n",
       " 83,\n",
       " 102,\n",
       " 54,\n",
       " 15,\n",
       " 6,\n",
       " 464,\n",
       " 39,\n",
       " 23,\n",
       " 176,\n",
       " 8,\n",
       " 5,\n",
       " 20,\n",
       " 403,\n",
       " 79,\n",
       " 61]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.set_best_n_clusters()\n",
    "cluster.get_clusters_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-based recommendation : user- et item- based <a id='memory'></a>\n",
    "\n",
    "Pour prédire la note d'un couple (*user*, *movie*) on peut regarder quelle note les utilisateurs similaires à *user* ont donné à ce film et faire une moyenne de leurs notes. On peut également regarder quelle note *user* a donné à des films similaires à *movie*. La première approche est centré sur les utilisateurs, *user-based*, tandis que la deuxième est centrée sur les films, *item-based*. Néanmoins les deux approches suivent la même logique et nous allons implémenter des fonctions qui s'adaptent en fonction de l'approche choisie. Dans un système *user-based*, nous allons appeler **peers** les **users** et **others** les **items**. Dans un système *item-based* c'est l'inverse.\n",
    "\n",
    "Deux utilisateurs sont considérés comme similaires s'ils ont les mêmes préférences de films. Il semble en effet plus pertinent de demander à un utilisateurs aux goûts similaires à *user* de lui conseiller un film. Pour comparer deux utilisateurs il faudra donc regarder les notes qu'ils ont donné aux mêmes films. De manière analogue, deux films sont similaires s'ils sont appréciés par les mêmes utilisateurs. Il faudra donc regarder les notes données par les mêmes utilisateurs pour comparer deux films. Cette notion de similitude sera calculée par un taux de corrélation.\n",
    "\n",
    "Nous rappelons ici l'algorithme proposé dans notre cours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des notes\n",
    "\n",
    "Nous n'avons besoin pour ce système que des notes données par les utilisateurs. Nous utiliserons donc seulement la table `ratings`. Puisque la moyenne des notes varie d'un utilisateur à un autre et d'un film à un autre, nous devons translater les notes afin que la moyenne des notes se trouve à 0. En *user-based*, on considère la moyenne par utilisateur, tandis qu'en *item-based* on s'interèsse à la moyenne par film. Par abus de langage nous appelons ces nouvelles notes les notes *normalisées*. Cette normalisation se fait via la méthode `__normalize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taux de corrélation\n",
    "\n",
    "\n",
    "Dans un système *user-based*, on note $I_u$ l'ensemble des items renseignés pour l'utilisateur $u$ et $U_k$ l'ensemble des utilisateurs qui ont notés le film $k$. On note $I_{uv} = I_u \\cap I_v$. Pour le *item-based* on utilisera les mêmes notations en intervertissant user et item. On notera également $s_{ui}$ la note normalisée de l'item *i* donnée par l'utilisateur *u*. \n",
    "\n",
    "\n",
    "Pour déterminer si deux utilisateurs se ressemblent en termes de goûts, nous utilisons un taux de corrélation sur les avis données. Nous allons comparer quatres taux de corrélations différents. Le premier ```cor()``` calcule le taux de corrélation classique donné par la formule :\n",
    "$$\n",
    "cor(u, v) = \\frac{\\sum_{k \\in I_{uv}} s_{uk} s_{vk}}{\\sqrt{\\sum_{k \\in I_{uv}} s_{uk}^2}\\sqrt{\\sum_{k \\in I_{uv}} s_{vk}^2}}\n",
    "$$\n",
    "\n",
    "Le taux de corrélation ajusté ```cor_adj()``` permet de ne pas donner trop d'importance aux films populaires que beaucoup de personnes ont vu.\n",
    "$$\n",
    "cor\\_adj(u, v) = \\frac{\\sum_{k \\in I_{uv}} s_{uk} s_{vk} / U_k}{\\sqrt{\\sum_{k \\in I_{uv}} \\frac{s_{uk}^2}{|U_k|}}\\sqrt{\\sum_{k \\in I_{uv}} \\frac{s_{vk}^2}{|U_k|}}}\n",
    "$$\n",
    "\n",
    "Le taux de correlation calculé par ```cor_dis()``` permet de ne pas donner une correlation trop élevée si les deux utilisateurs n'ont pas donné assez d'avis sur des films en commun. \n",
    "$$\n",
    "cor\\_dis(u, v) = cor(u, v) * \\frac{min(|I_{uv}|, \\beta)}{\\beta}\n",
    "$$\n",
    "\n",
    "Enfin la fonction ```cor_dis_adj()``` fait un mélange des deux dernières amélioration : il filtre les films trop populaire et n'apporte de l'importance seulement si deux personnes ont données leur avis sur un certain nombre de films.\n",
    "\n",
    "$$\n",
    "cor\\_dis(u, v) = cor\\_adj(u, v) * \\frac{min(|I_{uv}|, \\beta)}{\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tx_cor(u, v, dfr, base):\n",
    "    '''\n",
    "    :param: u, v - les id des peers (user ou movie) à comparer\n",
    "            base - un indicateur dy type de recommandation utilisé : 'user' ou 'movie'\n",
    "    :return: le taux de corrélation classique entre u et v.\n",
    "    '''\n",
    "    Iu = dfr.loc[u, :]\n",
    "    Iv = dfr.loc[v, :]\n",
    "    Iuv = list(set(Iu.index) & set(Iv.index))\n",
    "    if not len(Iuv) : # l'intersection est vide\n",
    "        return float('nan')\n",
    "\n",
    "    su = Iu.loc[Iuv]\n",
    "    sv = Iv.loc[Iuv]\n",
    "    su = su['rating_norm_'+base].to_numpy()\n",
    "    sv = sv['rating_norm_'+base].to_numpy()\n",
    "    \n",
    "    up = np.dot(su, sv)\n",
    "    down = math.sqrt(np.dot(su, su) * np.dot(sv, sv))\n",
    "\n",
    "# default value arbitrarily set to 0\n",
    "    if up == 0 or down == 0:\n",
    "        return 0\n",
    "    return up / down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">À adapter encore</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_adj(u, v, df, Iuv):\n",
    "    nb_rat = df.loc[:, ['movieId', 'rating']].groupby(['movieId']).count()\n",
    "    \n",
    "    sum_up = 0\n",
    "    sum_down_u = 0\n",
    "    sum_down_v = 0\n",
    "    for movie in Iuv.movieId.unique() :\n",
    "        suk = df.loc[(df['userId'] == u) & (df['movieId'] == movie), ['rating_norm_'+base]]\n",
    "        svk = df.loc[(df['userId'] == v) & (df['movieId'] == movie), ['rating_norm_'+base]]\n",
    "        suk, svk = float(suk), float(svk)\n",
    "        \n",
    "        sum_up += suk * svk / nb_rat.at[movie, 'rating']\n",
    "        sum_down_u += suk**2 /  nb_rat.at[movie, 'rating']\n",
    "        sum_down_v += svk**2 /  nb_rat.at[movie, 'rating']\n",
    "    return sum_up / math.sqrt(sum_down_u * sum_down_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_dis(u, v, df, Iuv):\n",
    "    beta = 20\n",
    "    correlation = cor(u, v, df, Iuv)\n",
    "    return correlation * min(len(Iuv), beta)/beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_dis_adj(u, v, df, Iuv):\n",
    "    beta = 20\n",
    "    correlation = cor_adj(u, v, df, Iuv)\n",
    "    return correlation * min(len(Iuv), beta)/beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice de corrélation\n",
    "\n",
    "Nous avons fait le choix d'utiliser un numpy array pour la matrice de corrélation. Puisque celle-ci est symétrique, nous stockons les données en double. Une première démarche avait été d'utiliser une dataframe à double indice où la valeur du premier indice était strictement inférieure à la valeur du deuxième. Néanmoins l'accès à une valeur dans une telle dataframe est beaucoup plus lente que dans un numpy array : la complexité est constante dans la numpy array. Nous avons préféré sacrifier un peu de compléxité en espace pour gagner considérablement en temps d'exécution.\n",
    "\n",
    "En utilsant une matrice, l'accès à un taux de corrélation se fait par des indices. Or il se peut que les id des peers ne soient pas consécutifs. Ceci est par exemple le cas lorsqu'on travaille avec un échantillon des données ou que des lignes ont été supprimées lors d'un nettoyage des données. Il faut alors établir une correspondance entre les id et les indices, que nous nommerons rank pour éviter la confusion orthographique. Pour cela nous utilisons un dictionnaire `id_rank` dont les clefs sont les id et les valeurs les rangs associés. \n",
    "\n",
    "\n",
    "La fonction de corrélation à utiliser doit être précisée. Nous utilisons également le module logging pour permettre le suivi du déroulement du calcul si précisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction\n",
    "\n",
    "Pour prédire la note qu'un utilisateur donnera à un film, nous faisons un moyenne des notes données pour les k *peer* les plus proches. Dans une approche *user-based*, on regarde donc les k plus proches utilisateurs, dans une approche *item-based*, les k films les plus proches. Les plus proches sont ceux qui ont une corrélation la plus élevée. On appelle **p** le peer et **o** l'élément other.\n",
    "\n",
    "La moyenne effectuée est pondérée par les coefficients de corrélations. On ajoute également la moyenne des notes de **p** pour retrouver une note non normalisée correspondant à l'échelle de note que l'utilisateur a tendance à donner.\n",
    "\n",
    "La prédiction de la note $\\hat{\\sigma}_{um}$ de l'user $u$ au film $m$ est :\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_{um} = \\mu_u + \\frac{\\sum_{v \\in P_u(m)} s_{vm} \\cdot cor(u, v)}{\\sum_{v \\in P_u(m)} |cor(u,v)|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MemoryBasedPredictor:\n",
    "    def __init__(self, base):\n",
    "        assert base in {'user', 'movie'}\n",
    "        self.base = base\n",
    "        self.ptype, self.otype = ('userId', 'movieId') if self.base == 'user' else ('movieId', 'userId')\n",
    "        self.dfr = None\n",
    "        self.cm = None\n",
    "        self.id_rank = None # explain what this is for\n",
    "        self.mean_peers = None\n",
    "    \n",
    "    def fit(self, ratings, cor_fct, verbose=False):\n",
    "        '''\n",
    "        Construit la matrice de correlation entre tous les peers présents dans ratings\n",
    "        \n",
    "        :param: ratings la dataframe contenant les notes des utilisateurs donnés aux films\n",
    "                cor_fct la fonction de corrélation à utiliser\n",
    "                verbose un booléen indiquant s'il faut afficher le suivi des calculs\n",
    "        '''\n",
    "        assert all(x in ratings.columns for x in ['userId', 'movieId', 'rating'])\n",
    "        \n",
    "        self.dfr = ratings[['userId', 'movieId', 'rating']].set_index([self.ptype, self.otype])\n",
    "        self.dfr.sort_index(inplace=True)\n",
    "\n",
    "        # normalize ratings per peer\n",
    "        self.mean_peers = self._normalize_()\n",
    "        \n",
    "        # construction of the correlation matrix\n",
    "        self._CorMatrix_(cor_fct, verbose)\n",
    "\n",
    "    def predict(self, p, o, k=4):\n",
    "        '''\n",
    "        :param: p l'id du peer\n",
    "                o l'id de other\n",
    "                k la taille des peer-groupes\n",
    "        :return: une note prédite pour le couple peer-other (p, o)\n",
    "        '''\n",
    "        assert self.dfr is not None, \"This MemoryBasedPredictor instance is not fitted yet. \\\n",
    "                                                Call 'fit' with appropriate arguments before using this estimator.\"\n",
    "        \n",
    "        # si peer et/ou other est inconnu, prédire des valeurs arbitraire\n",
    "        peer_unknown = p not in self.mean_peers\n",
    "        other_unknown = o not in self.dfr.index.droplevel(self.ptype)\n",
    "        \n",
    "        if peer_unknown and other_unknown:\n",
    "            return 2.5\n",
    "        elif peer_unknown:\n",
    "            return float(self.dfr.loc[(slice(None), o), 'rating'].mean())\n",
    "        elif other_unknown:\n",
    "            return self.mean_peers[p]\n",
    "        \n",
    "        mu = self.mean_peers[p]\n",
    "        peers = self._PeerGroup_(p, o, k)\n",
    "\n",
    "        # calculer la moyenne pondérée par le taux de corrélation des notes normalisés des amis dans le peer-groupe\n",
    "        sum_up, sum_down = 0, 0\n",
    "        for friend in peers:\n",
    "            cor = self.get_cor(p, friend)\n",
    "            if not math.isnan(cor):\n",
    "                sfo = self.dfr.loc[(friend, o), 'rating_norm_'+self.base]\n",
    "                sfo = 0 if len(sfo) <= 0 else float(sfo)\n",
    "                sum_up += sfo * cor\n",
    "                sum_down += abs(cor)\n",
    "\n",
    "        # valeur par défaut permettant de faire la divison (si sum_down est à 0, sum_up aussi) \n",
    "        sum_down = 1 if sum_down == 0 else sum_down\n",
    "        pred = mu + sum_up / sum_down\n",
    "\n",
    "        # note prédite à une précision de 0.5\n",
    "        pred = round(2 * pred) / 2\n",
    "        # note prédite se trouve entre 0 et 5\n",
    "        pred = 5 if pred > 5 else pred\n",
    "        pred = 0 if pred < 0 else pred\n",
    "\n",
    "        return pred\n",
    "        \n",
    "    def score(self, test_ratings, k=4):\n",
    "        '''\n",
    "        :param: test_ratings - l'échantillon de test\n",
    "                k - la taille des peer-groupes\n",
    "        :return: un score entre 0 et 1 correspondant à [1 - erreur]\n",
    "        '''\n",
    "        assert self.dfr is not None, \"This MemoryBasedPredictor instance is not fitted yet. \\\n",
    "                                                Call 'fit' with appropriate arguments before using this estimator.\"\n",
    "        dft = test_ratings.set_index([self.ptype, self.otype])\n",
    "        predictions = [self.predict(p, o, k) for (p, o) in list(dft.index)]\n",
    "        truth = dft['rating'].to_numpy()\n",
    "        \n",
    "        return 1 - math.sqrt(sum((predictions - truth)**2) / len(predictions)) / 5\n",
    "    \n",
    "    \n",
    "    def get_cor(self, u, v):\n",
    "        '''\n",
    "        :param: u, v deux id de peers\n",
    "        :return: le taux de corrélation entre u et v\n",
    "        '''\n",
    "        assert self.cm is not None, \"This MemoryBasedPredictor instance is not fitted yet. \\\n",
    "                                                Call 'fit' with appropriate arguments before using this estimator.\"\n",
    "        if u in self.id_rank and v in self.id_rank:\n",
    "            ixu, ivx = self.id_rank[u], self.id_rank[v]\n",
    "            return self.cm[ixu, ixv]\n",
    "        return float('nan') # valeur par défaut si pas de corrélation calculée\n",
    "    \n",
    "    def _normalize_(self):\n",
    "        '''\n",
    "        Ajoute une colonne dans la dataframe df contenant les notes normalisées des peers\n",
    "        :return: un dictionnaire de clefs les id des peers et de valeurs leurs notes moyennes\n",
    "        '''\n",
    "        mean = self.dfr.groupby(self.ptype).mean()['rating'].to_dict()\n",
    "        new_col = 'rating_norm_'+self.base\n",
    "        self.dfr[new_col] = self.dfr.apply(lambda row : row[0]- mean[row.name[0]] , axis=1) \n",
    "        return mean\n",
    "    \n",
    "    def _CorMatrix_(self, cor_fct, verbose=False):\n",
    "        '''\n",
    "        Construit la matrice de corrélation entre peers et le dictionnaire associant les id aux rangs\n",
    "        :param: cor_fct la fonction de corrélation à utiliser\n",
    "                verbose un booléen indiquant s'il faut affihcer le suivi des calculs\n",
    "        '''\n",
    "        peers = self.dfr.index.get_level_values(self.ptype).unique()\n",
    "        nb_peers = len(peers)\n",
    "\n",
    "        if verbose:\n",
    "            logger = logging.getLogger()\n",
    "            logger.setLevel(logging.INFO)\n",
    "            logging.info('nb of peers: {}'.format(nb_peers))\n",
    "\n",
    "        self.id_rank = {}\n",
    "        self.cm = np.empty((nb_peers,nb_peers))\n",
    "        self.cm[:] = np.nan\n",
    "\n",
    "        for i in range(nb_peers):\n",
    "            u = peers[i]\n",
    "            self.id_rank[u] = i\n",
    "            if verbose and not i % 10 : \n",
    "                logging.info('peer nb: {} (id {})'.format(i, u))\n",
    "            for j in range(i + 1, nb_peers):\n",
    "                v = peers[j]\n",
    "                tx_cor = cor_fct(u, v, self.dfr, self.base)\n",
    "                if not np.isnan(tx_cor):\n",
    "                    self.cm[i, j] = tx_cor\n",
    "                    self.cm[j, i] = self.cm[i, j]\n",
    "    \n",
    "    def _PeerGroup_(self, p, o, k=4):\n",
    "        '''\n",
    "        :param: p l'id du peer\n",
    "                o l'id de other\n",
    "                k la taille des peer-groupes\n",
    "        :return: la liste des k peers les plus proches de p\n",
    "        '''\n",
    "        # get peers that rated the other o\n",
    "        peers = self.dfr.loc[(slice(None), o), :]\n",
    "        peers = peers.index.get_level_values(self.ptype).unique()\n",
    "        \n",
    "        top = [(float('-inf'), p)] * k\n",
    "        for v in peers:\n",
    "            taux = self.get_cor(p, v)\n",
    "            if taux > top[-1][0] :\n",
    "                top += [(taux, v)]\n",
    "                top.sort(reverse=True)\n",
    "                top = top[:-1]\n",
    "        return [t[1] for t in top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:nb of peers: 73\n",
      "INFO:root:peer nb: 0 (id 5)\n",
      "INFO:root:peer nb: 10 (id 82)\n",
      "INFO:root:peer nb: 20 (id 190)\n",
      "INFO:root:peer nb: 30 (id 285)\n",
      "INFO:root:peer nb: 40 (id 386)\n",
      "INFO:root:peer nb: 50 (id 472)\n",
      "INFO:root:peer nb: 60 (id 554)\n",
      "INFO:root:peer nb: 70 (id 654)\n",
      "INFO:root:nb of peers: 98\n",
      "INFO:root:peer nb: 0 (id 111)\n",
      "INFO:root:peer nb: 10 (id 317)\n",
      "INFO:root:peer nb: 20 (id 1089)\n",
      "INFO:root:peer nb: 30 (id 1627)\n",
      "INFO:root:peer nb: 40 (id 2455)\n",
      "INFO:root:peer nb: 50 (id 2944)\n",
      "INFO:root:peer nb: 60 (id 3793)\n",
      "INFO:root:peer nb: 70 (id 5989)\n",
      "INFO:root:peer nb: 80 (id 26366)\n",
      "INFO:root:peer nb: 90 (id 84374)\n"
     ]
    }
   ],
   "source": [
    "# cellule de test provisoire\n",
    "\n",
    "dfr = ratings.sample(100)\n",
    "user_based = MemoryBasedPredictor('user')\n",
    "movie_based = MemoryBasedPredictor('movie')\n",
    "user_based.fit(dfr, tx_cor, verbose=True)\n",
    "movie_based.fit(dfr, tx_cor, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# cellule de test provisoire\n",
    "\n",
    "print(user_based.predict(5, 2))\n",
    "print(movie_based.predict(111, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-based recommendation system <a id='model'></a>\n",
    "\n",
    "[retour au sommaire](#sommaire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idée du modèle\n",
    "\n",
    "La matrice des notes user-item $R$ est partiellement vide. Ainsi réduire les dimensions de la matrice pourrait améliorer la complexité de nos algorithmes. Une méthode que nous pourrions avoir envie d'utiliser est la décomposision en valeurs singulières : $R = U_{svd} \\Sigma V_{svd}$. Cependant cette méthode ne s'applique pas ici étant donné que $R$ n'est pas complète et qu'on a besoin de réaliser des calculs algébriques avec $R$ pour trouver la décomposition.\n",
    "\n",
    "On considère donc un modèle dans lequel il existe des attributs (features) décrivants les films et les préférences des utilisateurs. La matrice $R$ peut alors être factorisée en produit de deux matrices $U$ et $V$ représentant respectivement les utilisateurs et les items :\n",
    "\n",
    "$$\n",
    "R \\approx U \\times V^T\n",
    "$$\n",
    "\n",
    "avec $R \\in \\mathbb{R}^{n \\times m}$ la matrice des notes user-item, $U \\in \\mathbb{R}^{n \\times \\ell}$ la matrice des users, $V \\in \\mathbb{R}^{m \\times \\ell}$ la matrice des items et $\\ell$ le nombre d'attributs. Pour faire un rapprochement avec la SVD, on peut considerer que $U = U_{svd} \\Sigma^{1/2}$ et $V = \\Sigma^{1/2} V_{svd}$. On note $U_i$ les lignes de $U$ et $V_j$ les lignes de $V$ :\n",
    "$\n",
    "U = \\left[ \\begin{array}{c} U_1 \\\\ \\vdots \\\\ U_n \\end{array} \\right]\n",
    "$ et \n",
    "$\n",
    "V = \\left[ \\begin{array}{c} V_1 \\\\ \\vdots \\\\ V_m \\end{array} \\right]\n",
    "$\n",
    "avec $U_i^T, V_j^T \\in \\mathbb{R^\\ell}$.\n",
    "\n",
    "Dans ce modèle, chaque note $R_{ij}$ associée à un couple user-item $(i, j)$ est le résultat du produit scalaire entre la ligne associée au user $i$ dans $U$ et la ligne associée au item $j$ dans $V$ : $R_{ij} = U_i \\cdot V_j^T$. Une fois les matrices $U$ et $V$ apprises, pour prédire une note il suffira de faire le produit scalaire entre les lignes correspondantes.\n",
    "\n",
    "Trouver $U$ et $V$ revient à minimiser l'erreur entre la note prédite $U_i \\cdot V_j^T$ et la véritable note $R_{ij}$. Il s'agit du problème de minimisation suivant, avec $E = \\{(i, j) \\mbox{ | } R_{ij} \\mbox{ connue}\\}$ :\n",
    "\n",
    "$$\n",
    "(U, V) = argmin_{(U, V)} \\sum_{(i, j) \\in E} [U_i \\cdot V_j^T - R_{ij}]^2\n",
    "$$\n",
    "\n",
    "qui est équivalent à:\n",
    "\n",
    "$$\n",
    "(U, V) = argmin_{(U, V)} \\frac{1}{2}\\sum_{(i, j) \\in E} [U_i \\cdot V_j^T - R_{ij}]^2 + \\lambda (\\|U_i\\|^2 + \\|V_j\\|^2)\n",
    "$$\n",
    "\n",
    "Le terme de droite est un terme régulateur, de paramètre $\\lambda$ à ajuster, permettant de prévenir un overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation avec une descente de gradient (à pas constant)\n",
    "\n",
    "<span style='color:blue'> justification du choix d'un SGD et pas regression plus classique : est-ce parce que c'est une somme sur E donc pas d'algèbre précise possible ? </span>\n",
    "\n",
    "Dans notre [cours d'optimisation](https://www.ceremade.dauphine.fr/~gontier/enseignement.html) donné par David Gontier, nous avons étudié différentes méthodes de descente de gradient de complexité et d'optimalité différentes. Cependant il nous semble qu'utiliser une version simple à pas $\\tau$ constant suffit.\n",
    "Notre fonction objective est la suivante :\n",
    "$$\n",
    "F(U, V) := \\sum_{(i, j) \\in E} \\frac{1}{2}[U_i \\cdot V_j^T - R_{ij}]^2 + \\frac{\\lambda}{2} (\\|U_i\\|^2 + \\|V_j\\|^2)\n",
    "$$\n",
    "\n",
    "Dans une descente de gradient classique, à chaque itération on met à jour $U$ et $V$ suivant la formule \n",
    "$\n",
    "(U, V) = (U, V) - \\tau \\nabla F(U, V)\n",
    "$. Cependant, dans notre cas nous n'allons pas mettre à jour toutes les lignes de $U$ et $V$ simultanément. En effet, puisque la somme dans $F$ ne se fait que sur les couples $(i, j)$ pour lesquels la note est connue, nous allons seulement mettre à jour le couple $(U_i, V_j)$ associé en itérant sur tous les couples $(i, j) \\in E$. \n",
    "\n",
    "Pour une note $R_{ij}$, on a \n",
    "$\n",
    "\\frac{\\partial F}{\\partial U_i} = V_j^T (U_i \\cdot V_j^T - R_{ij}) + \\lambda U_i\n",
    "$\n",
    " et \n",
    "$\n",
    "\\frac{\\partial F}{\\partial V_j} = Ui (U_i \\cdot V_j^T - R_{ij}) + \\lambda V_j\n",
    "$\n",
    "donc on peut mettre à jour les lignes $U_i$ et $V_j$ selon les formules \n",
    "$$\n",
    "U_i = Ui - \\tau [V_j^T (U_i \\cdot V_j^T - R_{ij}) + \\lambda U_i]\\\\\n",
    "V_j = V_j - \\tau [Ui (U_i \\cdot V_j^T - R_{ij}) + \\lambda V_j]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détails d'implémentation\n",
    "\n",
    "De même que pour le cas d'un prédicteur memory-based, nous avons fait le choix d'utiliser une matrice numpy pour représenter $R$. Celle-ci est certe essentiellement vide, mais l'accès est plus rapide et nous avons préféré privilégier le temps au coût d'un stockage inutil de vide. Néanmoins ceci nécessite également d'associer un id à un rang. Cette association doit pouvoir être faite dans les deux sens. Pour cela, nous utilisons une liste et un dictionnaire. Pour les user par exemple, `user_id` est une liste qui pour un rang donné permet d'avoir l'id correspondant : `user_id[i] = uid` où `i` est le rang correspondant à l'id `uid`. Pour avoir la correspondance dans l'ordre sens, nous utilisons le dictionnaire `user_rank` où `user_rank[uid] = i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBasedPredictor:\n",
    "    def __init__(self):\n",
    "        self.R = None\n",
    "        self.E = None\n",
    "        self.U = None\n",
    "        self.V = None\n",
    "        self.user_id = None\n",
    "        self.movie_id = None\n",
    "        self.user_rank = None\n",
    "        self.movie_rank = None\n",
    "    \n",
    "    def fit(self, ratings, ell=10, lamb=1/2, tau=1/10, tol=1e-3, Niter=1000, verbose=False):\n",
    "        '''\n",
    "        Apprentissage des paramètres U et V\n",
    "        \n",
    "        :param: ratings - la dataframe contenant les notes des utilisateurs donnés aux films\n",
    "                ell - le nombre de features du modèle\n",
    "                lamb - le terme de régularisation de la fonction objective\n",
    "                tau - le pas de la descente de gradient (taux d'apprentissage)\n",
    "                tol - la tolérance\n",
    "                Niter - le nombre d'itérations maximal\n",
    "                verbose - un booléen indiquant s'il faut afficher le suivi des calculs\n",
    "        '''\n",
    "        \n",
    "        if verbose:\n",
    "            logger = logging.getLogger()\n",
    "            logger.setLevel(logging.INFO)\n",
    "        \n",
    "        dfr = ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "        # correspondance rang - id\n",
    "        self.user_id = dfr['userId'].unique().tolist()\n",
    "        self.movie_id = dfr['movieId'].unique().tolist()\n",
    "        self.user_id.sort()\n",
    "        self.movie_id.sort()\n",
    "        # correspondance id - rang\n",
    "        self.user_rank, self.movie_rank = {}, {}\n",
    "        for uid in self.user_id:\n",
    "            self.user_rank[uid] = len(self.user_rank)\n",
    "        for mid in self.movie_id:\n",
    "            self.movie_rank[mid] = len(self.movie_rank)\n",
    "\n",
    "        # transformer la dataframe en matric numpy\n",
    "        dfr.set_index(['userId', 'movieId'], inplace=True)\n",
    "        self.R = dfr.unstack(level='movieId').to_numpy()\n",
    "            \n",
    "        # construction de l'ensemble E, ensemble des rangs pour lesquels R[i, j] est connu\n",
    "        ids = list(dfr.index)\n",
    "        self.E = list(map(lambda t : (self.user_rank[t[0]], self.movie_rank[t[1]]), ids))\n",
    "\n",
    "        n = len(self.user_rank)\n",
    "        m = len(self.movie_rank)\n",
    "\n",
    "        # initialisation aléatoire des paramètres U et V\n",
    "        self.U, self.V = np.random.rand(n, ell), np.random.rand(m, ell)\n",
    "        \n",
    "        # résolution du problème d'optimisation\n",
    "        self._descenteGradient_(lamb, tau, tol, Niter, verbose=verbose)\n",
    "    \n",
    "    def fit_linear_approach(self, ratings, clu_fea, lamb=1/2, tau=1/10, tol=1e-3, Niter=1000, verbose=False):\n",
    "        \n",
    "        dfr = ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "        # correspondance rang - id\n",
    "        self.user_id = dfr['userId'].unique().tolist()\n",
    "        self.movie_id = dfr['movieId'].unique().tolist()\n",
    "        self.user_id.sort()\n",
    "        self.movie_id.sort()\n",
    "        # correspondance id - rang\n",
    "        self.user_rank, self.movie_rank = {}, {}\n",
    "        for uid in self.user_id:\n",
    "            self.user_rank[uid] = len(self.user_rank)\n",
    "        for mid in self.movie_id:\n",
    "            self.movie_rank[mid] = len(self.movie_rank)\n",
    "\n",
    "        # transformer la dataframe en matric numpy\n",
    "        dfr.set_index(['userId', 'movieId'], inplace=True)\n",
    "        self.R = dfr.unstack(level='movieId').to_numpy()\n",
    "        \n",
    "        # construction de l'ensemble E, ensemble des rangs pour lesquels R[i, j] est connu\n",
    "        ids = list(dfr.index)\n",
    "        self.E = list(map(lambda t : (self.user_rank[t[0]], self.movie_rank[t[1]]), ids))\n",
    "        \n",
    "        # construction de la matrice V a partir du DataFrame clu_fea\n",
    "        V = select_useful_features(clu_fea)\n",
    "        V = normalize_runtime(V)\n",
    "        V = normalize_release_date(V)\n",
    "        V = normalize_lang(V)\n",
    "        V = normalize_genres(V)\n",
    "        V = normalize_prod_countries(V)\n",
    "        self.V = V\n",
    "        ell = V.shape[1]\n",
    "        n = len(self.user_rank)\n",
    "        self.U = np.random.rand(n, ell)\n",
    "        \n",
    "        self._descenteGradient_(lamb, tau, tol, Niter, linear=True, verbose=verbose)\n",
    "        \n",
    "    def predict(self, uid, mid):\n",
    "        '''\n",
    "        :param: uid - l'id de l'utilisateur\n",
    "                mid - l'id du film\n",
    "        :return: la note prédite pour le couple user-movie (uid, mid)\n",
    "        '''\n",
    "        assert self.E is not None, \"This ModelBasedPredictor instance is not fitted yet. \\\n",
    "                                                Call 'fit' with appropriate arguments before using this estimator.\"\n",
    "        ell = self.U.shape[1]\n",
    "        \n",
    "        # selection des lignes correspondantes, vecteurs aléatoires si inconnus\n",
    "        u = self.U[self.user_rank[uid]] if uid in self.user_rank else np.random.rand(ell)\n",
    "        v = self.V[self.movie_rank[mid]] if mid in self.movie_rank else np.random.rand(ell)\n",
    "        \n",
    "        #prédiction\n",
    "        pred = np.dot(u, v.T)\n",
    "        pred = round(2 * pred) / 2 # la note prédite à une précision de 0.5\n",
    "        pred = 5 if pred > 5 else pred # la note prédite se trouve entre 0 et 5\n",
    "        pred = 0 if pred < 0 else pred\n",
    "        \n",
    "        return pred\n",
    "\n",
    "    \n",
    "    def score(self, test_ratings):\n",
    "        '''\n",
    "        :param: test_ratings l'échantillon de test\n",
    "        :return: un score entre 0 et 1 correspondant à [1 - erreur]\n",
    "        '''\n",
    "        assert self.E is not None, \"This ModelBasedPredictor instance is not fitted yet. \\\n",
    "                                                Call 'fit' with appropriate arguments before using this estimator.\"\n",
    "        \n",
    "        dft = test_ratings.set_index(['userId', 'movieId'])\n",
    "        predictions = [self.predict(uid, mid) for (uid, mid) in list(dft.index)]\n",
    "        truth = dft['rating'].to_numpy()\n",
    "    \n",
    "        return 1 - math.sqrt(sum((predictions - truth)**2) / len(predictions) ) / 5\n",
    "        \n",
    "\n",
    "    def _F_(self, lamb):\n",
    "        '''\n",
    "        :param: lamb - le terme régulateur\n",
    "        :return: l'évaluation de la fonction objective à minimiser avec les paramètres actuels U et V\n",
    "        '''\n",
    "        return sum([1/2 * (np.dot(self.U[i], self.V[j].T) - self.R[i, j])**2 \\\n",
    "                    + lamb/2 * (sum(self.U[i] ** 2) + sum(self.V[j] ** 2))  for (i, j) in self.E])\n",
    "    \n",
    "    def _F_linear_(self, lamb):\n",
    "        return sum([1/2 * (np.dot(self.U[i], self.V[j]) - self.R[i, j])**2 \\\n",
    "                    + lamb/2 * sum(self.U[i] ** 2) for (i, j) in self.E])\n",
    "    \n",
    "    def _descenteGradient_(self, lamb, tau, tol=1e-3, Niter=1000, linear=False, verbose=False):\n",
    "        '''\n",
    "        Réalise une descente de gradient pour minimiser la fonction objective.\n",
    "    \n",
    "        :param: lamb - le terme de régularisation de la fonction objective\n",
    "                tau - le pas de la descente de gradient (taux d'apprentissage)\n",
    "                tol - la tolérance\n",
    "                Niter - le nombre d'itérations maximal\n",
    "                linear - un booléen indiquant si la fonction objective à minimiser correspond au modèle linéaire\n",
    "                verbose - un booléen indiquant s'il faut afficher le suivi des calculs\n",
    "        '''\n",
    "        if verbose:\n",
    "            logging.info('nombre de couples : {}'.format(len(self.E)))\n",
    "            logging.info(\"nombre d'iteration max : {}\".format(Niter))\n",
    "            \n",
    "        last_F = 0\n",
    "        for n in range(Niter):\n",
    "            \n",
    "            new_F = self._F_linear_(lamb) if linear else self._F_(lamb)\n",
    "\n",
    "            if verbose :\n",
    "                logging.info(\"{}. pente de F: {}\".format(n, abs(new_F - last_F)))\n",
    "\n",
    "            if abs(new_F - last_F) < tol:\n",
    "                return\n",
    "            last_F = new_F   \n",
    "\n",
    "            for (i, j) in self.E:\n",
    "                gradU = self.V[j].T * (np.dot(self.U[i], self.V[j].T) - self.R[i, j]) + lamb * self.U[i]\n",
    "                self.U[i] -= tau * gradU\n",
    "                if not linear:\n",
    "                    gradV = self.U[i] * (np.dot(self.U[i], self.V[j].T) - self.R[i, j]) + lamb * self.V[j]\n",
    "                    self.V[j] -= tau * gradV\n",
    "        print(\"Erreur, l’algorithme n’a pas convergé après\", Niter ,\" itérations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:nombre de couples : 100\n",
      "INFO:root:nombre d'iteration max : 1000\n",
      "INFO:root:0. pente de F: 281.70351338756376\n",
      "INFO:root:1. pente de F: 74.78778980798671\n",
      "INFO:root:2. pente de F: 18.126968412230212\n",
      "INFO:root:3. pente de F: 7.667027318558695\n",
      "INFO:root:4. pente de F: 4.91998646629051\n",
      "INFO:root:5. pente de F: 3.6774409161306494\n",
      "INFO:root:6. pente de F: 2.8956992945634283\n",
      "INFO:root:7. pente de F: 2.3297934969233722\n",
      "INFO:root:8. pente de F: 1.8939459180506333\n",
      "INFO:root:9. pente de F: 1.5484596739366054\n",
      "INFO:root:10. pente de F: 1.2707912914918325\n",
      "INFO:root:11. pente de F: 1.046058497102365\n",
      "INFO:root:12. pente de F: 0.8634419469486829\n",
      "INFO:root:13. pente de F: 0.7146433242466514\n",
      "INFO:root:14. pente de F: 0.5931240480159659\n",
      "INFO:root:15. pente de F: 0.4936660701516189\n",
      "INFO:root:16. pente de F: 0.412081153512446\n",
      "INFO:root:17. pente de F: 0.3449990625927626\n",
      "INFO:root:18. pente de F: 0.289704463043563\n",
      "INFO:root:19. pente de F: 0.24400781754047784\n",
      "INFO:root:20. pente de F: 0.20614198669792927\n",
      "INFO:root:21. pente de F: 0.1746791171191262\n",
      "INFO:root:22. pente de F: 0.14846384370468968\n",
      "INFO:root:23. pente de F: 0.12655968399027984\n",
      "INFO:root:24. pente de F: 0.10820609061190112\n",
      "INFO:root:25. pente de F: 0.09278408548411221\n",
      "INFO:root:26. pente de F: 0.0797887768192993\n",
      "INFO:root:27. pente de F: 0.0688073776164515\n",
      "INFO:root:28. pente de F: 0.05950161057850778\n",
      "INFO:root:29. pente de F: 0.05159360545889058\n",
      "INFO:root:30. pente de F: 0.04485457592568309\n",
      "INFO:root:31. pente de F: 0.03909570964322029\n",
      "INFO:root:32. pente de F: 0.034160822765045395\n",
      "INFO:root:33. pente de F: 0.029920423503710936\n",
      "INFO:root:34. pente de F: 0.02626690337856985\n",
      "INFO:root:35. pente de F: 0.023110633054955088\n",
      "INFO:root:36. pente de F: 0.020376785587785662\n",
      "INFO:root:37. pente de F: 0.018002746034170514\n",
      "INFO:root:38. pente de F: 0.015935994869920478\n",
      "INFO:root:39. pente de F: 0.014132375146687082\n",
      "INFO:root:40. pente de F: 0.012554671127048778\n",
      "INFO:root:41. pente de F: 0.011171440256987353\n",
      "INFO:root:42. pente de F: 0.009956051603182914\n",
      "INFO:root:43. pente de F: 0.008885892853015775\n",
      "INFO:root:44. pente de F: 0.007941715176968955\n",
      "INFO:root:45. pente de F: 0.007107091035010171\n",
      "INFO:root:46. pente de F: 0.00636796465468592\n",
      "INFO:root:47. pente de F: 0.005712278672092452\n",
      "INFO:root:48. pente de F: 0.005129663459371159\n",
      "INFO:root:49. pente de F: 0.0046111781271633845\n",
      "INFO:root:50. pente de F: 0.00414909418930165\n",
      "INFO:root:51. pente de F: 0.0037367145045834604\n",
      "INFO:root:52. pente de F: 0.0033682214302643843\n",
      "INFO:root:53. pente de F: 0.003038549208383756\n",
      "INFO:root:54. pente de F: 0.00274327648511985\n",
      "INFO:root:55. pente de F: 0.0024785355847996016\n",
      "INFO:root:56. pente de F: 0.002240935751899542\n",
      "INFO:root:57. pente de F: 0.002027498061664801\n",
      "INFO:root:58. pente de F: 0.0018356000910557668\n",
      "INFO:root:59. pente de F: 0.0016629287763123557\n",
      "INFO:root:60. pente de F: 0.0015074401434560514\n",
      "INFO:root:61. pente de F: 0.001367324830397365\n",
      "INFO:root:62. pente de F: 0.001240978489107647\n",
      "INFO:root:63. pente de F: 0.0011269763177494951\n",
      "INFO:root:64. pente de F: 0.0010240510903258837\n",
      "INFO:root:65. pente de F: 0.0009310741585011328\n"
     ]
    }
   ],
   "source": [
    "# cellule de tes provisoire\n",
    "\n",
    "dfr = ratings.sample(100)\n",
    "model_based = ModelBasedPredictor()\n",
    "model_based.fit(dfr, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df, train_prop):\n",
    "    '''\n",
    "    Sépare la dataframe df en deux dataframe train et test.\n",
    "    :param: df la dataframe à séparer\n",
    "            train_prop la proportion d'element qu'il doit y avoir dans le train dataframe\n",
    "            seed la graine du générateur aléatoire\n",
    "    :return: les train et test dataframes\n",
    "    '''\n",
    "    train = df.sample(frac=train_prop)\n",
    "    test = df.drop(train.index)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(df, nb_folds):\n",
    "    '''\n",
    "    Sépare la dataframe df en nb_folds dataframe de taille (presque) égales.\n",
    "    :param: df la dataframe à séparer\n",
    "            nb_folds le nombre d'échantillons à consitutuer à partir de df\n",
    "    :return: la liste des dataframes\n",
    "    '''\n",
    "    N = len(df)\n",
    "    f_size = N // nb_folds\n",
    "    folds = [None] * nb_folds\n",
    "    for i in range(nb_folds - 1):\n",
    "        folds[i] = df.sample(n=f_size)\n",
    "        df = df.drop(folds[i].index)\n",
    "    folds[nb_folds - 1] = df\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(predictor, df, params, nb_folds):\n",
    "    \n",
    "    # verification que les arguments donnés dans le dictionnaire params correspondent bien aux paramètre de predictor\n",
    "    var = getattr(getattr(predictor.fit, '__code__'), 'co_varnames')\n",
    "    assert set(params.keys()) <= set(var[1:]), 'invalid arguments given in params' # var[1:] pour enlever 'self'\n",
    "    \n",
    "    \n",
    "    folds = k_fold(df, nb_folds)\n",
    "    scores = [None] * nb_folds\n",
    "    \n",
    "    for i in range(nb_folds):\n",
    "        test = folds[i]\n",
    "        train = df.drop(test.index)\n",
    "        \n",
    "        pred = predictor()\n",
    "        pred.fit(train, **params)\n",
    "        scores[i] = pred.score(test)\n",
    "    \n",
    "    return sum(scores) / nb_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinaisons(grid):\n",
    "    for v in product(*grid.values()):\n",
    "        yield {id:v[i] for i, id in enumerate(grid.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(predictor, df, param_grid, cv, verbose=False):\n",
    "    best_score = 0\n",
    "    best_param = None\n",
    "    for param in combinaisons(param_grid):\n",
    "        score = cross_validation(predictor, df, param, cv)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_param = param\n",
    "        \n",
    "        if verbose:\n",
    "            print('CV score: {} for param: {}'.format(score, param))\n",
    "\n",
    "    return best_score, best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'ell' : [75, 100, 125, 150],\n",
    "    'lamb' : [0.2, 1.0, 2.0],\n",
    "    'tau' : [0.001, 0.01, 0.1]}\n",
    "bs, bp = gridSearch(ModelBasedPredictor, ratings.sample(100), param_grid, cv=2, verbose=True)\n",
    "print(bs, bp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_linear = movies.join(link.set_index('tmdbId'), on='tmdbId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm_linear = dfm_linear.merge(ratings.drop_duplicates('movieId'), how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_linear = ratings.merge(dfm_linear.movieId, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ModelBasedPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f ModelBasedPredictor._descenteGradient_ test.fit_linear_approach(ratings_linear, dfm_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model : content-based\n",
    "\n",
    "On remarque que si $U$ ou $V$ est fixé, la fonction objective devient quadratique. Or nous connaissons des algorithmes efficaces pour minimiser des fonctions quadratiques. De plus, une matrice d'attributs des films peut être donnée puisqu'on connaît certaines informations sur les films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_useful_features(V):\n",
    "    return V[['genres', 'release_date', 'production_countries', 'original_language', 'runtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = select_useful_features(dfm_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_runtime(dfm_arg):\n",
    "    dfm = dfm_arg.copy()\n",
    "    min_runtime = min(dfm.runtime)\n",
    "    max_runtime_diff = max(dfm.runtime) - min_runtime\n",
    "    if max_runtime_diff <= 1:\n",
    "        return dfm\n",
    "    dfm.runtime = dfm.runtime.apply(lambda x: (x - min_runtime) / max_runtime_diff)\n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = normalize_runtime(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_release_date(dfm_arg):\n",
    "    dfm = dfm_arg.copy()\n",
    "    simplify_date(dfm)\n",
    "    min_date = min(dfm.release_date)\n",
    "    max_date_diff = max(dfm.release_date) - min_date\n",
    "    if max_date_diff <= 1:\n",
    "        return dfm\n",
    "    dfm.release_date = dfm.release_date.apply(lambda x: (x - min_date) / max_date_diff)\n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = normalize_release_date(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lang(dfm_arg):\n",
    "    dfm = dfm_arg.copy()\n",
    "    if 'original_language' not in dfm.columns:\n",
    "        return dfm\n",
    "    languages = np.unique(dfm.original_language)\n",
    "    nb_lang = len(languages)\n",
    "    for lang in languages:\n",
    "        dfm[lang] = pd.Series()\n",
    "        dfm[lang] = dfm[lang].fillna(0)\n",
    "    for index, lang in dfm.original_language.iteritems():\n",
    "        dfm.at[index, lang] = 1\n",
    "    dfm = dfm.drop('original_language', axis=1)\n",
    "    \n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = normalize_lang(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_genres(dfm_arg):\n",
    "    dfm = dfm_arg.copy()\n",
    "    if 'genres' not in dfm.columns:\n",
    "        return dfm\n",
    "    vectorize_genres(dfm)\n",
    "    genres_list = np.array([])\n",
    "    for _, tab in dfm.genres.iteritems():\n",
    "        genres_list = np.unique(np.append(genres_list, tab))\n",
    "    for genre_id in genres_list:\n",
    "        col_name = \"genId\" + str(int(genre_id))\n",
    "        dfm[col_name] = pd.Series()\n",
    "        dfm[col_name] = dfm[col_name].fillna(0)\n",
    "    for index, gen in dfm.genres.iteritems():\n",
    "        for g in gen:\n",
    "            dfm.at[index, \"genId\" + str(g)] = 1 / len(gen)\n",
    "    dfm = dfm.drop('genres', axis=1)\n",
    "    \n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = normalize_genres(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_prod_countries(dfm_arg):\n",
    "    dfm = dfm_arg.copy()\n",
    "    if 'production_countries' not in dfm:\n",
    "        return dfm\n",
    "    simplify_countries(dfm)\n",
    "    country_list = np.array([])\n",
    "    for _, tab in dfm.production_countries.iteritems():\n",
    "        country_list = np.unique(np.append(country_list, tab))\n",
    "    for country in country_list:\n",
    "        dfm[country] = pd.Series()\n",
    "        dfm[country] = dfm[country].fillna(0)\n",
    "    for index, countries in dfm.production_countries.iteritems():\n",
    "        for c in countries:\n",
    "            dfm.at[index, c] = 1 / len(countries)\n",
    "    dfm = dfm.drop('production_countries', axis=1)\n",
    "    \n",
    "    return dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = normalize_prod_countries(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>af</th>\n",
       "      <th>ar</th>\n",
       "      <th>bn</th>\n",
       "      <th>bo</th>\n",
       "      <th>bs</th>\n",
       "      <th>cn</th>\n",
       "      <th>cs</th>\n",
       "      <th>da</th>\n",
       "      <th>...</th>\n",
       "      <th>TT</th>\n",
       "      <th>TW</th>\n",
       "      <th>UA</th>\n",
       "      <th>UG</th>\n",
       "      <th>US</th>\n",
       "      <th>UY</th>\n",
       "      <th>VN</th>\n",
       "      <th>XC</th>\n",
       "      <th>ZA</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.071053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.091228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.088596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.111404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.092982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9021</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.074561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9022</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.135965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9025 rows × 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      release_date   runtime   af   ar   bn   bo   bs   cn   cs   da  ...  \\\n",
       "0         0.815789  0.071053  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1         0.815789  0.091228  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2         0.815789  0.088596  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3         0.815789  0.111404  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4         0.815789  0.092982  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...            ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "9020      1.000000  0.074561  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "9021      0.868421  0.074561  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "9022      1.000000  0.131579  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "9023      1.000000  0.135965  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "9024      1.000000  0.086842  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "       TT   TW   UA   UG   US   UY   VN   XC   ZA   ZW  \n",
       "0     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "9020  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9021  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9022  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9023  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "9024  0.0  0.0  0.0  0.0  0.5  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[9025 rows x 156 columns]"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthode hybride <a id='hybride'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle hybride : popularité par genre et collaborative filtering\n",
    "\n",
    "La méthode précédente permet de prédire une note, mais nous aimerions pouvoir recommander des films à un utilisateurs qu'il est susceptible d'aimer. Pour cela il faudrait prédire la note qu'il donnerait à tous les films qu'il n'a pas encore noté et prélever ceux dont la note prédite est la plus élevée. Ceci serait beaucoup trop coûteux. Une première solution est de ne considérer que des films appartenant à ses genres préférés. Ceci risque d'être toujours trop coûteux, alors nous allons nous restreindre qu'aux films les plus populaires dans ses genres préférés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryPopularityRecommender:\n",
    "    def __init__(self, base):\n",
    "        self.memory = MemoryBasedPredictor(base)\n",
    "        self.popularity = None\n",
    "    \n",
    "    def fit(self, movies, ratings, link, cor_fct, verbose=False):\n",
    "        self.popularity = PopularityRecommender(movies, ratings, link)\n",
    "        \n",
    "        self.memory.fit(ratings, cor_fct, verbose)\n",
    "    \n",
    "    def recommend(self, uid, nb_reco=20, k=4):\n",
    "        dfm_filtered = self.popularity.recommend(uid, nb_reco*10)\n",
    "        \n",
    "        predictions = pd.DataFrame(columns=['movieId', 'predict_rating'])\n",
    "        for mid in dfm_filtered.index.unique():\n",
    "            p, o = (uid, mid) if self.memory.base == 'user' else (mid, uid)\n",
    "            rat = (self.memory).predict(p, o, k)\n",
    "            predictions = predictions.append({'movieId':int(mid), 'predict_rating':rat}, ignore_index=True)\n",
    "        \n",
    "        predictions.sort_values(by='predict_rating', ascending=False, inplace=True)\n",
    "        reco = dfm_filtered.join(predictions.set_index('movieId'))\n",
    "        reco = reco.head(nb_reco) if reco.shape[0] > nb_reco else reco\n",
    "        return reco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette solution présente néanmoins un désavantage. Premièrement, seuls les films les plus populaires sont considérés, leur donnant plus de visibilté parmis les utilisateurs. Ainsi un nouveau film qui n'aura pas beaucoup été vu aura que peut de chance d'être recommandé par assez populaire. Le deuxième problème est que cette méthode regroupe les films par genres. Or ce qui caractérise un film est plus vaste que seulement la case dans laquelle il s'inscrit et peut dépendre du réalisateur, du lieu de tournage ou de pleins d'autres facteurs. C'est ici que le *clustering* nous vient en aide. Cela permet de regrouper les films selon leurs similitudes issues de méta-informations et ainsi d'affiner la recherche."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
